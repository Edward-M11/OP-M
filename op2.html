

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>2 &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'op2';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Caso no separable general" href="punto3.html" />
    <link rel="prev" title="Introducción" href="introduc.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/uninorte.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/uninorte.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Informe Proyecto Final Optimizacion Matematica
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduc.html">Introducción</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2</a></li>

<li class="toctree-l1"><a class="reference internal" href="punto3.html"><strong>Caso no separable general</strong></a></li>





<li class="toctree-l1"><a class="reference internal" href="metodo.html">Objetivo</a></li>





<li class="toctree-l1"><a class="reference internal" href="conclu.html">Conclusiones</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fop2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/op2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>2</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">2</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-no-separable">Caso no Separable</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#puntos-en-la-frontera-o-fuera-del-margen-en-el-lado-correcto-del-clasificador">1. Puntos en la frontera o fuera del margen en el lado correcto del clasificador:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#puntos-en-el-lado-correcto-del-clasificador-pero-dentro-del-margen">2. Puntos en el lado correcto del clasificador, pero dentro del margen:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#puntos-que-se-encuentran-en-el-lugar-equivocado-del-clasificador">3. Puntos que se encuentran en el lugar equivocado del clasificador:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graficamente">Graficamente:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#derivacion-del-lagrangiano">Derivación del Lagrangiano</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-a-un-problema-de-optimizacion">Aplicación a un Problema de Optimización</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-en-optimizacion-de-svm">Ejemplo en Optimización de SVM</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#formulacion-del-problema-dual-de-svm-no-separable">Formulación del Problema Dual de SVM No Separable</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-de-las-condiciones-kkt">Aplicación de las Condiciones KKT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#condiciones-de-estacionariedad">Condiciones de Estacionariedad:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#condiciones-de-complementariedad">Condiciones de Complementariedad:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#condiciones-de-holgura-primal-y-dual">Condiciones de Holgura Primal y Dual:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formulacion-del-problema-dual">Formulación del Problema Dual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion-del-modelo">Implementación del modelo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocesamiento">Preprocesamiento</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manual">Manual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#auto">Auto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusión</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>2<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h1>
<p>Usando lo visto en clase y las condiciones KKT, escriba el problema dual de SVM para el caso
no separable más general (con variables de holgura y función transformadora φ). Con la función
<code class="docutils literal notranslate"><span class="pre">quadprog</span></code> de Matlab (o su equivalente en Python o cualquier otro lenguaje de su escogencia) y un
código para la función de generalización de su autoría, resuelva el problema con la base de datos flor
de iris (<a class="reference external" href="https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris">https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris</a>) para clasificar las clases de
plantas Iris-Setosa e Iris-Virgínica. Use varios valores de C y diferentes tipos de kernels. Determine
el error de su clasificación en cada caso y obtenga conclusiones.</p>
<section id="caso-no-separable">
<h2>Caso no Separable<a class="headerlink" href="#caso-no-separable" title="Permalink to this heading">#</a></h2>
<p>Antes de empezar a desarrollar cada iten de esta parte 2 entenderemos lo que son los casos no separble. Se entiende como caso no seprable cuando no existe un clasificador lineal que pueda clasificar correctamente todos los puntos por ende algunos errores de clasificación pueden ocurrir. Existen tres tipos de puntos mal clasificados.</p>
<section id="puntos-en-la-frontera-o-fuera-del-margen-en-el-lado-correcto-del-clasificador">
<h3>1. Puntos en la frontera o fuera del margen en el lado correcto del clasificador:<a class="headerlink" href="#puntos-en-la-frontera-o-fuera-del-margen-en-el-lado-correcto-del-clasificador" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>es decir cuando: $<span class="math notranslate nohighlight">\( y_n f(\mathbf{x}_n) \geq 1  \)</span>$</p></li>
<li><p>Estos puntos se encuentran en la frontera del margen de decisión o en el lado correcto, pero potencialmente fuera del margen. No cometen errores de clasificación.</p></li>
<li><p>Variables de holgura: <span class="math notranslate nohighlight">\( \xi_n = 0 \)</span> ya que estos puntos no requieren ninguna holgura para ser clasificados correctamente.</p></li>
</ul>
</section>
<section id="puntos-en-el-lado-correcto-del-clasificador-pero-dentro-del-margen">
<h3>2. Puntos en el lado correcto del clasificador, pero dentro del margen:<a class="headerlink" href="#puntos-en-el-lado-correcto-del-clasificador-pero-dentro-del-margen" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Cuando: $<span class="math notranslate nohighlight">\( 0 &lt; y_n f(\mathbf{x}_n) &lt; 1 \)</span>$</p></li>
<li><p>Estos puntos están correctamente clasificados pero se encuentran dentro del margen. Cometen un error de margen.</p></li>
<li><p>Variables de holgura: <span class="math notranslate nohighlight">\( 0 &lt; \xi_n &lt; 1 \)</span>. El valor de <span class="math notranslate nohighlight">\( \xi_n \)</span> mide el grado de violación del margen por parte del punto correspondiente.</p></li>
</ul>
<p>Las variables de holgura <span class="math notranslate nohighlight">\( \xi_n \)</span> son fundamentales en la formulación del problema de optimización de SVM. Permiten que el modelo tolere ciertas violaciones del margen, siendo reguladas por el parámetro de penalización <span class="math notranslate nohighlight">\( C \)</span>, y forman parte del objetivo de minimización en la función de coste de SVM.</p>
</section>
<section id="puntos-que-se-encuentran-en-el-lugar-equivocado-del-clasificador">
<h3>3. Puntos que se encuentran en el lugar equivocado del clasificador:<a class="headerlink" href="#puntos-que-se-encuentran-en-el-lugar-equivocado-del-clasificador" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Cuando: <span class="math notranslate nohighlight">\(y_n f(\mathbf{x}_n) \leq 0\)</span></p></li>
<li><p>Estos puntos están mal clasificados y se encuentran en el lado incorrecto del hiperplano de decisión.</p></li>
<li><p>Variables de holgura: <span class="math notranslate nohighlight">\(\xi_n \geq 1\)</span>. Estos valores indican una violación considerable del margen, ya que no solo están dentro del margen, sino que están completamente en el lado equivocado.</p></li>
</ul>
</section>
<section id="graficamente">
<h3>Graficamente:<a class="headerlink" href="#graficamente" title="Permalink to this heading">#</a></h3>
<p><img alt="Descripción de la imagen" src="_images/imagen1.png" /></p>
<ul class="simple">
<li><p><strong>Línea sólida</strong>: Representa el hiperplano de decisión donde <span class="math notranslate nohighlight">\(f(\mathbf{x}) = 0\)</span>.</p></li>
<li><p><strong>Líneas discontinuas</strong>: Representan el margen del clasificador donde <span class="math notranslate nohighlight">\(f(\mathbf{x}) = 1\)</span> y <span class="math notranslate nohighlight">\(f(\mathbf{x}) = -1\)</span>.</p></li>
<li><p><strong>Símbolos</strong>:</p>
<ul>
<li><p><strong>Estrellas</strong>: Puntos fuera o en los límites del margen y clasificados correctamente.</p></li>
<li><p><strong>Círculos</strong>: Puntos dentro del margen, aún del lado correcto, pero cometiendo u</p></li>
</ul>
</li>
</ul>
</section>
<section id="derivacion-del-lagrangiano">
<h3>Derivación del Lagrangiano<a class="headerlink" href="#derivacion-del-lagrangiano" title="Permalink to this heading">#</a></h3>
<p>Consideremos un problema de optimización de la siguiente forma:</p>
<ul class="simple">
<li><p><strong>Función Objetivo</strong>: <span class="math notranslate nohighlight">\(f(x)\)</span>, que queremos maximizar o minimizar.</p></li>
<li><p><strong>Restricciones</strong>: <span class="math notranslate nohighlight">\(g_i(x) = 0\)</span>, donde <span class="math notranslate nohighlight">\(i\)</span> varía de 1 a <span class="math notranslate nohighlight">\(m\)</span>, siendo <span class="math notranslate nohighlight">\(m\)</span> el número total de restricciones de igualdad.</p></li>
</ul>
<p>Para incorporar las restricciones dentro de la función objetivo, introducimos los multiplicadores de Lagrange <span class="math notranslate nohighlight">\(\lambda_i\)</span> para cada restricción <span class="math notranslate nohighlight">\(g_i(x)\)</span> y construimos la función Lagrangiana <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> como:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(x, \lambda) = f(x) + \sum_{i=1}^{m} \lambda_i g_i(x)
\]</div>
<p>Aquí, <span class="math notranslate nohighlight">\(x\)</span> representa el vector de variables de decisión y <span class="math notranslate nohighlight">\(\lambda\)</span> el vector de multiplicadores de Lagrange.</p>
</section>
<section id="aplicacion-a-un-problema-de-optimizacion">
<h3>Aplicación a un Problema de Optimización<a class="headerlink" href="#aplicacion-a-un-problema-de-optimizacion" title="Permalink to this heading">#</a></h3>
<p>Para aplicar el Lagrangiano a un problema de optimización, seguimos los siguientes pasos:</p>
<ol class="arabic simple">
<li><p><strong>Formulación del Lagrangiano</strong>: Combinamos la función objetivo y las restricciones en la función Lagrangiana.</p></li>
<li><p><strong>Encontrar las Condiciones de Estacionariedad</strong>: Derivamos el Lagrangiano con respecto a todas las variables, incluyendo los multiplicadores de Lagrange, y buscamos los puntos donde estas derivadas se anulan. Esto nos da un sistema de ecuaciones para resolver.</p></li>
<li><p><strong>Verificar Otras Condiciones (KKT)</strong>: Para problemas con restricciones de desigualdad, necesitamos verificar las condiciones de Karush-Kuhn-Tucker, que incluyen la factibilidad primal y dual, la complementariedad y la condición de slack.</p></li>
<li><p><strong>Interpretación de los Multiplicadores de Lagrange</strong>: Los valores de los multiplicadores de Lagrange en la solución óptima nos indican la sensibilidad de la función objetivo ante cambios marginales en las restricciones.</p></li>
</ol>
</section>
<section id="ejemplo-en-optimizacion-de-svm">
<h3>Ejemplo en Optimización de SVM<a class="headerlink" href="#ejemplo-en-optimizacion-de-svm" title="Permalink to this heading">#</a></h3>
<p>En el contexto de Máquinas de Soporte Vectorial (SVM) para clasificación, buscamos maximizar el margen entre las dos clases sujetas a que todas las muestras estén correctamente clasificadas. El Lagrangiano para el problema de optimización de SVM con variables de holgura <span class="math notranslate nohighlight">\(\xi\)</span> (para permitir clasificaciones erróneas) y una función de transformación <span class="math notranslate nohighlight">\(\phi\)</span> (para mapear las muestras a un espacio donde sean linealmente separables) es:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(w, b, \xi, \lambda, \mu) = \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i - \sum_{i=1}^{n} \lambda_i [y_i (w^T \phi(x_i) + b) - 1 + \xi_i] - \sum_{i=1}^{n} \mu_i \xi_i
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(w\)</span> es el vector de pesos del hiperplano.</p></li>
<li><p><span class="math notranslate nohighlight">\(b\)</span> es el término de sesgo del hiperplano.</p></li>
<li><p><span class="math notranslate nohighlight">\(\xi\)</span> es el vector de variables de holgura.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> es el parámetro de penalización para las variables de holgura.</p></li>
<li><p><span class="math notranslate nohighlight">\(\lambda\)</span> y <span class="math notranslate nohighlight">\(\mu\)</span> son los multiplicadores de Lagrange que aplican las restricciones del problema.</p></li>
</ul>
<p>El uso de la función <span class="math notranslate nohighlight">\(\phi\)</span> permite aplicar el truco del kernel en SVM, lo que facilita el cálculo de los productos internos en un espacio dimensional superior sin la necesidad de calcular la transformación explícitamente.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="formulacion-del-problema-dual-de-svm-no-separable">
<h1>Formulación del Problema Dual de SVM No Separable<a class="headerlink" href="#formulacion-del-problema-dual-de-svm-no-separable" title="Permalink to this heading">#</a></h1>
<p>La formulación del problema dual de SVM no separable comienza con la función de Lagrange asociada al problema de optimización primal.</p>
<p>El Lagrangiano ( L ) es dado por:</p>
<div class="math notranslate nohighlight">
\[
L(\mathbf{w}, b, \boldsymbol{\xi}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^{n} \xi_i - \sum_{i=1}^{n} \lambda_i [y_i(\mathbf{w}^T \mathbf{x}_i + b) - 1 + \xi_i] - \sum_{i=1}^{n} \mu_i \xi_i
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}\)</span> es el vector de pesos del hiperplano.</p></li>
<li><p><span class="math notranslate nohighlight">\(b\)</span> es el término de sesgo del hiperplano.</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\xi}\)</span> es el vector de variables de holgura.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span> es el parámetro de penalización para las variables de holgura.</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\lambda}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> son los multiplicadores de Lagrange.</p></li>
</ul>
<section id="aplicacion-de-las-condiciones-kkt">
<h2>Aplicación de las Condiciones KKT<a class="headerlink" href="#aplicacion-de-las-condiciones-kkt" title="Permalink to this heading">#</a></h2>
<p>Para obtener el problema dual, aplicamos las condiciones de Karush-Kuhn-Tucker (KKT).</p>
<section id="condiciones-de-estacionariedad">
<h3>Condiciones de Estacionariedad:<a class="headerlink" href="#condiciones-de-estacionariedad" title="Permalink to this heading">#</a></h3>
<p>Las derivadas parciales del Lagrangiano respecto a <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, <span class="math notranslate nohighlight">\(b\)</span>, y <span class="math notranslate nohighlight">\(\boldsymbol{\xi}\)</span> deben ser cero.</p>
<div class="math notranslate nohighlight">
\[
\nabla_{\mathbf{w}} L = \mathbf{w} - \sum_{i=1}^{n} \lambda_i y_i \mathbf{x}_i = 0 \quad \Rightarrow \quad \mathbf{w} = \sum_{i=1}^{n} \lambda_i y_i \mathbf{x}_i
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial L}{\partial b} = \sum_{i=1}^{n} \lambda_i y_i = 0
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial L}{\partial \xi_i} = C - \lambda_i - \mu_i = 0 \quad \Rightarrow \quad \lambda_i + \mu_i = C, \quad \forall i
\]</div>
</section>
<section id="condiciones-de-complementariedad">
<h3>Condiciones de Complementariedad:<a class="headerlink" href="#condiciones-de-complementariedad" title="Permalink to this heading">#</a></h3>
<p>Para los multiplicadores de Lagrange, se debe cumplir:</p>
<div class="math notranslate nohighlight">
\[
\lambda_i [y_i(\mathbf{w}^T \mathbf{x}_i + b) - 1 + \xi_i] = 0 \quad \forall i
\]</div>
<div class="math notranslate nohighlight">
\[
\mu_i \xi_i = 0 \quad \forall i
\]</div>
</section>
<section id="condiciones-de-holgura-primal-y-dual">
<h3>Condiciones de Holgura Primal y Dual:<a class="headerlink" href="#condiciones-de-holgura-primal-y-dual" title="Permalink to this heading">#</a></h3>
<p>Las restricciones originales y las variables de holgura deben cumplir:</p>
<div class="math notranslate nohighlight">
\[
y_i(\mathbf{w}^T \mathbf{x}_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad \lambda_i \geq 0, \quad \mu_i \geq 0 \quad \forall i
\]</div>
</section>
</section>
<section id="formulacion-del-problema-dual">
<h2>Formulación del Problema Dual<a class="headerlink" href="#formulacion-del-problema-dual" title="Permalink to this heading">#</a></h2>
<p>Sustituimos <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\xi}\)</span> en el Lagrangiano y maximizamos respecto a <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}\)</span> con las restricciones anteriores. El problema dual resultante es:</p>
<p>Maximizar respecto a <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
W(\boldsymbol{\lambda}) = \sum_{i=1}^{n} \lambda_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \lambda_i \lambda_j y_i y_j \mathbf{x}_i^T \mathbf{x}_j
\]</div>
<p>Sujeto a:</p>
<div class="math notranslate nohighlight">
\[
0 \leq \lambda_i \leq C, \quad \sum_{i=1}^{n} \lambda_i y_i = 0
\]</div>
<p>Este es el problema dual de SVM no separable. Resolviendo este problema obtenemos los multiplicadores de Lagrange que luego podemos utilizar para construir nuestro clasificador SVM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Cargamos el conjunto de datos Iris</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Convertimos a un DataFrame de Pandas</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="o">.</span><span class="n">from_codes</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>

<span class="c1"># Creamos un gráfico 3D interactivo</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter_3d</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;sepal length (cm)&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;sepal width (cm)&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="s1">&#39;petal length (cm)&#39;</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;species&#39;</span><span class="p">)</span>

<span class="c1"># Mostrar el gráfico</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\Users\Edward Morales\miniconda3\envs\ml_venv\lib\site-packages\plotly\express\_core.py:2044: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped = df.groupby(required_grouper, sort=False)  # skip one_group groupers
</pre></div>
</div>
</div>
</div>
<p>Filtro los datos a los que necesito para el ejercicio, borramos las filas “setosa”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#renombro el df</span>
<span class="n">column_names</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nombres de columnas de características:&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1">#filtro, quito versicolor</span>
<span class="n">iris_df_filtered</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;setosa&#39;</span><span class="p">]</span>
<span class="k">if</span> <span class="s1">&#39;setosa&#39;</span> <span class="ow">in</span> <span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">:</span>
    <span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">remove_categories</span><span class="p">([</span><span class="s1">&#39;setosa&#39;</span><span class="p">])</span>

<span class="c1">#defino X &amp; y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris_df_filtered</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>


<span class="c1">#Vemos sus caracteristicas</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Nombres de columnas de características: [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;, &#39;species&#39;]
       sepal length  sepal width  petal length  petal width
count    100.000000   100.000000    100.000000   100.000000
mean       6.262000     2.872000      4.906000     1.676000
std        0.662834     0.332751      0.825578     0.424769
min        4.900000     2.000000      3.000000     1.000000
25%        5.800000     2.700000      4.375000     1.300000
50%        6.300000     2.900000      4.900000     1.600000
75%        6.700000     3.025000      5.525000     2.000000
max        7.900000     3.800000      6.900000     2.500000
count            100
unique             2
top       versicolor
freq              50
Name: class, dtype: object
class
versicolor    50
virginica     50
Name: count, dtype: int64
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Edward Morales\AppData\Local\Temp\ipykernel_92220\1321155144.py:9: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.2f&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="_images/c3f7976edf4d9de4e82888cefb78fda646177da512356b9c4d6ccaa8ef12b69d.png" src="_images/c3f7976edf4d9de4e82888cefb78fda646177da512356b9c4d6ccaa8ef12b69d.png" />
</div>
</div>
<p>Vemos que en esta matriz de confucion hay diferentes correlaciones y aplicamos nuevamente el VIF</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.tools</span> <span class="kn">import</span> <span class="n">add_constant</span>

<span class="c1"># Asumiendo que &#39;X&#39; es tu DataFrame y ya tiene las columnas de interés</span>

<span class="n">df_with_const</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Calcula el VIF para cada variable predictora</span>
<span class="n">vif_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>  <span class="c1"># Usa &#39;pd.DataFrame()&#39; en lugar de &#39;X.DataFrame()&#39;</span>
<span class="n">vif_data</span><span class="p">[</span><span class="s2">&quot;Variable&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_with_const</span><span class="o">.</span><span class="n">columns</span>
<span class="n">vif_data</span><span class="p">[</span><span class="s2">&quot;VIF&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">df_with_const</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df_with_const</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vif_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       Variable         VIF
0         const  125.170277
1  sepal length    3.990113
2   sepal width    1.721954
3  petal length    7.252447
4   petal width    3.948354
</pre></div>
</div>
</div>
</div>
<p>Eliminar la variable “petal length” ya que es la que tiene el VIF más alto, al hacer esto nos quedamos con variables más importantes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.tools</span> <span class="kn">import</span> <span class="n">add_constant</span>

<span class="c1"># Asumiendo que &#39;X&#39; es tu DataFrame y ya tiene las columnas de interés</span>
<span class="n">VIX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">df_with_const</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">VIX</span><span class="p">)</span>

<span class="c1"># Calcula el VIF para cada variable predictora</span>
<span class="n">vif_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>  <span class="c1"># Usa &#39;pd.DataFrame()&#39; en lugar de &#39;X.DataFrame()&#39;</span>
<span class="n">vif_data</span><span class="p">[</span><span class="s2">&quot;Variable&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_with_const</span><span class="o">.</span><span class="n">columns</span>
<span class="n">vif_data</span><span class="p">[</span><span class="s2">&quot;VIF&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">df_with_const</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df_with_const</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vif_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       Variable         VIF
0         const  122.240203
1  sepal length    1.730834
2   sepal width    1.649553
3   petal width    1.766067
</pre></div>
</div>
</div>
</div>
<p>En este caso todas tiene un VIF muy cercano a 1, lo que es perfecto ya que 1 represneta que no existe multicolinealidad (en el rango de 1 a 5)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">VIX</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.2f&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="_images/d8b46a02e3ada02b4549470ddd181374c3c975a2c5f59be6447b455c0cab29e8.png" src="_images/d8b46a02e3ada02b4549470ddd181374c3c975a2c5f59be6447b455c0cab29e8.png" />
</div>
</div>
<p>Nos quendamos nuevamente con las variables más importates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris_df_filtered</span> <span class="o">=</span> <span class="n">iris_df_filtered</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal length&quot;</span><span class="p">])</span> <span class="c1"># Quito la columna petal length del df</span>
</pre></div>
</div>
</div>
</div>
<p>Me quedo con VIX, como la svaribles explicativas, y las etiquetas e iris_df como el data frame</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">iris_df_filtered</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7ca8c2ceba15c58f87453f575c32532792c5b52607fc8c58c2c10005804da07a.png" src="_images/7ca8c2ceba15c58f87453f575c32532792c5b52607fc8c58c2c10005804da07a.png" />
</div>
</div>
<p>En este caso se ve que los datos estan mucho más juntos y es realmente dificil separalos lienalmente.</p>
</section>
<section id="implementacion-del-modelo">
<h2>Implementación del modelo<a class="headerlink" href="#implementacion-del-modelo" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris_df_filtered</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length</th>
      <th>sepal width</th>
      <th>petal width</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>50</th>
      <td>7.0</td>
      <td>3.2</td>
      <td>1.4</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>51</th>
      <td>6.4</td>
      <td>3.2</td>
      <td>1.5</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>52</th>
      <td>6.9</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>53</th>
      <td>5.5</td>
      <td>2.3</td>
      <td>1.3</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>54</th>
      <td>6.5</td>
      <td>2.8</td>
      <td>1.5</td>
      <td>versicolor</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter_3d</span><span class="p">(</span><span class="n">iris_df_filtered</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="s1">&#39;petal width&#39;</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="n">symbol</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">)</span>


<span class="c1"># Mostrar el gráfico</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Y aun graficando 3D se ven los datos muy pegado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objs</span> <span class="k">as</span> <span class="nn">go</span>


<span class="c1"># Codificamos las etiquetas de clase</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>

<span class="c1"># Entrenamos el clasificador SVM con un kernel lineal</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris_df_filtered</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]],</span> <span class="n">y_encoded</span><span class="p">)</span>

<span class="c1"># Coeficientes del hiperplano</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercept_</span>

<span class="c1"># Creamos un gráfico 3D interactivo usando plotly express</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter_3d</span><span class="p">(</span><span class="n">iris_df_filtered</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="s1">&#39;petal width&#39;</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="n">symbol</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">)</span>

<span class="c1"># Creamos la malla para el hiperplano</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">50</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;sepal width&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">iris_df_filtered</span><span class="p">[</span><span class="s1">&#39;sepal width&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">zz</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">xx</span> <span class="o">-</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">yy</span> <span class="o">-</span> <span class="n">v</span><span class="p">)</span> <span class="o">/</span> <span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># Añadimos el hiperplano al gráfico</span>
<span class="n">fig</span><span class="o">.</span><span class="n">add_traces</span><span class="p">(</span><span class="n">go</span><span class="o">.</span><span class="n">Surface</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">xx</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">yy</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="n">zz</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;SVM Hyperplane&#39;</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">showscale</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># Mostrar el gráfico</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Y podemos ver como aun con todos los datos hiperplano dado por SVM comote muchos errores.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>


<span class="n">iris_df</span> <span class="o">=</span> <span class="n">iris_df_filtered</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Separa las clases</span>
<span class="n">versicolor</span> <span class="o">=</span> <span class="n">iris_df</span><span class="p">[</span><span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;versicolor&#39;</span><span class="p">]</span>
<span class="n">virginica</span> <span class="o">=</span> <span class="n">iris_df</span><span class="p">[</span><span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;virginica&#39;</span><span class="p">]</span>

<span class="c1"># Selecciona 5 muestras aleatorias de cada clase para el conjunto de prueba</span>
<span class="n">versicolor_test</span> <span class="o">=</span> <span class="n">versicolor</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">virginica_test</span> <span class="o">=</span> <span class="n">virginica</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Concatena las muestras de prueba en un único DataFrame</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">versicolor_test</span><span class="p">,</span> <span class="n">virginica_test</span><span class="p">])</span>

<span class="c1"># Elimina las muestras de prueba del DataFrame original para obtener el conjunto de entrenamiento</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">iris_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">test_df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="c1"># Ahora tienes tus conjuntos de entrenamiento y prueba</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Conjunto de Entrenamiento:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Conjunto de Prueba:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>

<span class="c1"># Si necesitas las características y las etiquetas por separado:</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Conjunto de Entrenamiento:
    sepal length  sepal width  petal width       class
1            7.1          3.0          2.1   virginica
2            6.5          3.2          2.0   virginica
3            6.1          2.8          1.2  versicolor
4            6.0          3.0          1.8   virginica
5            6.5          2.8          1.5  versicolor
..           ...          ...          ...         ...
94           6.2          3.4          2.3   virginica
95           6.8          2.8          1.4  versicolor
97           6.3          3.3          1.6  versicolor
98           7.7          3.0          2.3   virginica
99           6.0          2.2          1.5   virginica

[90 rows x 4 columns]

Conjunto de Prueba:
    sepal length  sepal width  petal width       class
96           5.8          2.7          1.0  versicolor
58           6.1          3.0          1.4  versicolor
10           5.5          2.5          1.3  versicolor
0            5.7          2.6          1.0  versicolor
74           6.2          2.2          1.5  versicolor
49           6.1          2.6          1.4   virginica
62           6.4          2.8          2.2   virginica
20           7.7          3.8          2.2   virginica
73           6.7          3.0          2.3   virginica
42           6.9          3.2          2.3   virginica
</pre></div>
</div>
</div>
</div>
<p>Separo los datos en entrenamiento y testeo para escalarlos.</p>
</section>
<section id="preprocesamiento">
<h2>Preprocesamiento<a class="headerlink" href="#preprocesamiento" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>

<span class="n">min_on_training</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">min_on_training</span><span class="o">.</span><span class="n">shape</span>

<span class="n">range_on_training</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">range_on_training</span><span class="o">.</span><span class="n">shape</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span> <span class="o">/</span> <span class="n">range_on_training</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Minimum for each feature</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum for each feature</span><span class="se">\n</span><span class="s2"> </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Minimum for each feature
sepal length    0.0
sepal width     0.0
petal width     0.0
dtype: float64
Maximum for each feature
 sepal length    1.0
sepal width     1.0
petal width     1.0
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span> <span class="o">/</span> <span class="n">range_on_training</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.956
Accuracy on test set: 0.900
</pre></div>
</div>
</div>
</div>
<p>Entrenamos un modelo con los parametros por defecto y vemos que su puntaje Accuracy (datos bien clasificados / todos los datos)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc_C01</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">.001</span><span class="p">)</span>
<span class="n">svc_C01</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.944
Accuracy on test set: 0.900
</pre></div>
</div>
</div>
</div>
<p>Provando con un <span class="math notranslate nohighlight">\(C\)</span> diferente vemos como empeora, ahora veremos unos graficos que los mostratan de mejor forma.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># Asumiendo que tienes dos conjuntos de datos: &#39;train_df&#39; y &#39;test_df&#39;</span>
<span class="c1"># Primero, selecciona solo las columnas que vas a utilizar para el entrenamiento y las etiquetas</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]</span>  <span class="c1"># Reemplaza con las características que deseas usar</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;virginica&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;versicolor&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Codifica las clases a valores numéricos</span>

<span class="c1"># Escala las características</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Valores de C y gamma para probar, en escala logarítmica</span>
<span class="n">C_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">gamma_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>

<span class="c1"># Crear subplots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">C</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C_values</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gamma_values</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="c1"># Entrena el modelo SVM</span>
        <span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">)</span>
        <span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Crea una malla de puntos para dibujar la frontera de decisión</span>
        <span class="n">h</span> <span class="o">=</span> <span class="mf">.02</span>  <span class="c1"># Tamaño del paso en la malla</span>
        <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X_train_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X_train_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>

        <span class="c1"># Predice las etiquetas para cada punto en la malla y redimensiona para el gráfico</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># Dibuja la frontera de decisión y los puntos de datos</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">coolwarm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">coolwarm</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;C=</span><span class="si">{</span><span class="n">C</span><span class="si">}</span><span class="s1">, gamma=</span><span class="si">{</span><span class="n">gamma</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Mostrar el gráfico</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a5f42dbf4ec5cf5785d943d2c7cf10b7816629cbd26901d907e04fe42c70720f.png" src="_images/a5f42dbf4ec5cf5785d943d2c7cf10b7816629cbd26901d907e04fe42c70720f.png" />
</div>
</div>
<p>Aqui se entreno otro modelo, con solo dos caracteristicas para asi poder graficar como cambia el funcionamiento con los diferentes parametros</p>
<p>Entrnado el SVM con diferentes hiperparametros vemos como cada uno obtiene diferestes resultados y devemos escoger el que tenga mejores resultados para poder predecir.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>


<span class="n">iris_df</span> <span class="o">=</span> <span class="n">iris_df_filtered</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Separa las clases</span>
<span class="n">versicolor</span> <span class="o">=</span> <span class="n">iris_df</span><span class="p">[</span><span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;versicolor&#39;</span><span class="p">]</span>
<span class="n">virginica</span> <span class="o">=</span> <span class="n">iris_df</span><span class="p">[</span><span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;virginica&#39;</span><span class="p">]</span>

<span class="c1"># Selecciona 5 muestras aleatorias de cada clase para el conjunto de prueba</span>
<span class="n">versicolor_test</span> <span class="o">=</span> <span class="n">versicolor</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="n">virginica_test</span> <span class="o">=</span> <span class="n">virginica</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>

<span class="c1"># Concatena las muestras de prueba en un único DataFrame</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">versicolor_test</span><span class="p">,</span> <span class="n">virginica_test</span><span class="p">])</span>

<span class="c1"># Elimina las muestras de prueba del DataFrame original para obtener el conjunto de entrenamiento</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">iris_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">test_df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="c1"># Ahora tienes tus conjuntos de entrenamiento y prueba</span>
<span class="c1">#print(&quot;Conjunto de Entrenamiento:&quot;)</span>
<span class="c1">#print(train_df)</span>
<span class="c1">#print(&quot;\nConjunto de Prueba:&quot;)</span>
<span class="c1">#print(test_df)</span>

<span class="c1"># Si necesitas las características y las etiquetas por separado:</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>

<span class="n">min_on_training</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">min_on_training</span><span class="o">.</span><span class="n">shape</span>

<span class="n">range_on_training</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">range_on_training</span><span class="o">.</span><span class="n">shape</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span> <span class="o">/</span> <span class="n">range_on_training</span>

<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span> <span class="o">/</span> <span class="n">range_on_training</span>


<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="s1">&#39;virginica&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y_test_encoded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="s1">&#39;virginica&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="manual">
<h2>Manual<a class="headerlink" href="#manual" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cvxopt</span> <span class="kn">import</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">solvers</span>

<span class="k">def</span> <span class="nf">train_svm</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))))</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">C</span><span class="p">)))</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">solvers</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;show_progress&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">solution</span> <span class="o">=</span> <span class="n">solvers</span><span class="o">.</span><span class="n">qp</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">solution</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">support_vectors</span> <span class="o">=</span> <span class="n">lambdas</span> <span class="o">&gt;</span> <span class="mf">1e-5</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lambdas</span><span class="p">))[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">lambdas</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">sv</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">sv_y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">y_k</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">*</span> <span class="n">sv_y</span> <span class="o">*</span> <span class="n">K</span><span class="p">[</span><span class="n">ind_k</span><span class="p">,</span> <span class="n">support_vectors</span><span class="p">])</span>
                 <span class="k">for</span> <span class="n">ind_k</span><span class="p">,</span> <span class="n">y_k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span>

<span class="k">def</span> <span class="nf">svm_predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">*</span> <span class="n">sv_y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sv</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># Ejemplo de uso</span>
<span class="c1"># Asumiendo que X_train_scaled y y_train son tus datos y etiquetas de entrenamiento ya preparados</span>
<span class="n">C_value</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># Puedes cambiar este valor según sea necesario</span>
<span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">train_svm</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C_value</span><span class="p">)</span>
<span class="n">y_test_predicted</span> <span class="o">=</span> <span class="n">svm_predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># Aquí puedes usar y_test_predicted para calcular métricas o realizar otras tareas</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test_predicted</span>


<span class="c1"># Calculamos la matriz de confusión y mostramos los errores</span>
<span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Calculamos los errores</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>  
<span class="n">FN</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>


<span class="c1"># Calculamos las métricas de evaluación</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualizamos la matriz de confusión como un mapa de calor</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Verdaderos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicciones&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Para graficar predicho vs real, necesitamos una visualización 2D</span>
<span class="c1"># Esto solo tiene sentido si estamos trabajando con 2 características</span>
<span class="c1"># Si es el caso, podemos graficar las características en los ejes y colorear según predicho/real</span>
<span class="k">if</span> <span class="n">X_test_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicho&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.9
Precision: 0.8333333333333334
Recall: 1.0
F1 Score: 0.9090909090909091
</pre></div>
</div>
<img alt="_images/3a0a50457233a5eb099afc6b19467b6a5e852a80c7257d6eb6d73d5121747efa.png" src="_images/3a0a50457233a5eb099afc6b19467b6a5e852a80c7257d6eb6d73d5121747efa.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cvxopt</span> <span class="kn">import</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">solvers</span>

<span class="k">def</span> <span class="nf">train_svm_poly</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">K_poly</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">coef0</span><span class="p">)</span> <span class="o">**</span> <span class="n">degree</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">*</span> <span class="n">K_poly</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))))</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">C</span><span class="p">)))</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">solvers</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;show_progress&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">solution</span> <span class="o">=</span> <span class="n">solvers</span><span class="o">.</span><span class="n">qp</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">solution</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">support_vectors</span> <span class="o">=</span> <span class="n">lambdas</span> <span class="o">&gt;</span> <span class="mf">1e-5</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lambdas</span><span class="p">))[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">lambdas</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">sv</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">sv_y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">y_k</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">*</span> <span class="n">sv_y</span> <span class="o">*</span> <span class="n">K_poly</span><span class="p">[</span><span class="n">ind_k</span><span class="p">,</span> <span class="n">support_vectors</span><span class="p">])</span>
                 <span class="k">for</span> <span class="n">ind_k</span><span class="p">,</span> <span class="n">y_k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span>

<span class="k">def</span> <span class="nf">svm_predict_poly</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">K_poly_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sv</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">coef0</span><span class="p">)</span> <span class="o">**</span> <span class="n">degree</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">*</span> <span class="n">sv_y</span> <span class="o">*</span> <span class="n">K_poly_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># Ejemplo de uso</span>
<span class="c1"># Asumiendo que X_train_scaled y y_train son tus datos y etiquetas de entrenamiento ya preparados</span>
<span class="n">C_value</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># Puedes cambiar este valor según sea necesario</span>
<span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">train_svm_poly</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C_value</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">y_test_predicted</span> <span class="o">=</span> <span class="n">svm_predict_poly</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Aquí puedes usar y_test_predicted para calcular métricas o realizar otras tareas</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test_predicted</span>


<span class="c1"># Calculamos la matriz de confusión y mostramos los errores</span>
<span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Calculamos los errores</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>  
<span class="n">FN</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>


<span class="c1"># Calculamos las métricas de evaluación</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualizamos la matriz de confusión como un mapa de calor</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Verdaderos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicciones&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Para graficar predicho vs real, necesitamos una visualización 2D</span>
<span class="c1"># Esto solo tiene sentido si estamos trabajando con 2 características</span>
<span class="c1"># Si es el caso, podemos graficar las características en los ejes y colorear según predicho/real</span>
<span class="k">if</span> <span class="n">X_test_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicho&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.9666666666666667
Precision: 1.0
Recall: 0.9333333333333333
F1 Score: 0.9655172413793104
</pre></div>
</div>
<img alt="_images/48bf410f8ebafa5c6bacbb480ce5cf7b241c5ad13c79480b94cee4085eaac616.png" src="_images/48bf410f8ebafa5c6bacbb480ce5cf7b241c5ad13c79480b94cee4085eaac616.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cvxopt</span> <span class="kn">import</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">solvers</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">train_svm_rbf</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">K_rbf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">K_rbf</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">*</span> <span class="n">K_rbf</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))))</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">C</span><span class="p">)))</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">solvers</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;show_progress&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">solution</span> <span class="o">=</span> <span class="n">solvers</span><span class="o">.</span><span class="n">qp</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">solution</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">support_vectors</span> <span class="o">=</span> <span class="n">lambdas</span> <span class="o">&gt;</span> <span class="mf">1e-5</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lambdas</span><span class="p">))[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">lambdas</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">sv</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="n">sv_y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">support_vectors</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">y_k</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">*</span> <span class="n">sv_y</span> <span class="o">*</span> <span class="n">K_rbf</span><span class="p">[</span><span class="n">ind_k</span><span class="p">,</span> <span class="n">support_vectors</span><span class="p">])</span>
                 <span class="k">for</span> <span class="n">ind_k</span><span class="p">,</span> <span class="n">y_k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span>

<span class="k">def</span> <span class="nf">svm_predict_rbf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># Convierte a array si aún no lo es</span>
    <span class="n">K_rbf_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">K_rbf_pred</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">sv</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">*</span> <span class="n">sv_y</span> <span class="o">*</span> <span class="n">K_rbf_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># Ejemplo de uso</span>
<span class="c1"># Asumiendo que X_train_scaled y y_train son tus datos y etiquetas de entrenamiento ya preparados</span>
<span class="n">C_value</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Puedes cambiar este valor según sea necesario</span>
<span class="n">gamma_value</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Puedes cambiar este valor según sea necesario</span>
<span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">train_svm_rbf</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C_value</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma_value</span><span class="p">)</span>
<span class="n">y_test_predicted</span> <span class="o">=</span> <span class="n">svm_predict_rbf</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">sv</span><span class="p">,</span> <span class="n">sv_y</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma_value</span><span class="p">)</span>

<span class="c1"># Aquí puedes usar y_test_predicted para calcular métricas o realizar otras tareas</span>


<span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test_predicted</span>


<span class="c1"># Calculamos la matriz de confusión y mostramos los errores</span>
<span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Calculamos los errores</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>  
<span class="n">FN</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">conf_mat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>


<span class="c1"># Calculamos las métricas de evaluación</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualizamos la matriz de confusión como un mapa de calor</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Verdaderos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicciones&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Para graficar predicho vs real, necesitamos una visualización 2D</span>
<span class="c1"># Esto solo tiene sentido si estamos trabajando con 2 características</span>
<span class="c1"># Si es el caso, podemos graficar las características en los ejes y colorear según predicho/real</span>
<span class="k">if</span> <span class="n">X_test_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test_encoded</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicho&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.9
Precision: 1.0
Recall: 0.8
F1 Score: 0.888888888888889
</pre></div>
</div>
<img alt="_images/3ad9f8e5782481b16760602d86b93354589c9c9884a1589b67617fdb9925f3d4.png" src="_images/3ad9f8e5782481b16760602d86b93354589c9c9884a1589b67617fdb9925f3d4.png" />
</div>
</div>
</section>
<section id="auto">
<h2>Auto<a class="headerlink" href="#auto" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># Asumiendo que &#39;train_df&#39; es tu DataFrame y ya está definido con los datos correctos</span>

<span class="c1"># Utilizamos todas las características disponibles, excepto la columna &#39;class&#39;</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X_train_scaled</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y_train</span>



<span class="c1"># Define la cuadrícula de parámetros a probar</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
     <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
     <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">],</span>
     <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]},</span>
     <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;poly&#39;</span><span class="p">],</span>
     <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="p">]</span>

<span class="c1"># Realiza la búsqueda en cuadrícula</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Muestra los mejores parámetros y la mejor puntuación de validación cruzada</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor puntuación de validación cruzada: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>

<span class="c1"># Opcionalmente, puedes usar el mejor modelo encontrado para hacer predicciones</span>
<span class="c1"># Recuerda que necesitarás tener un &#39;X_test_scaled&#39; que esté preparado de manera similar a &#39;X_train_scaled&#39;</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros: {&#39;C&#39;: 0.001, &#39;gamma&#39;: 10, &#39;kernel&#39;: &#39;rbf&#39;}
Mejor puntuación de validación cruzada: 0.95
SVC(C=0.001, gamma=10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="c1"># Calcula la matriz de confusión y muestra el informe de clasificación</span>
<span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Informe de Clasificación:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Visualiza la matriz de confusión como un mapa de calor</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Verdaderos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicciones&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matriz de Confusión:
[[10  0]
 [ 1  9]]

Informe de Clasificación:
              precision    recall  f1-score   support

  versicolor       0.91      1.00      0.95        10
   virginica       1.00      0.90      0.95        10

    accuracy                           0.95        20
   macro avg       0.95      0.95      0.95        20
weighted avg       0.95      0.95      0.95        20
</pre></div>
</div>
<img alt="_images/fa5c2f339d9212914864d73dbe1bb551516fafe3262519f87781100dd808293c.png" src="_images/fa5c2f339d9212914864d73dbe1bb551516fafe3262519f87781100dd808293c.png" />
</div>
</div>
</section>
<section id="conclusion">
<h2>Conclusión<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h2>
<p>SVM para este caso logro un muy buen resultados ya que apasar de ser datos no separables logra identificar correctamente las etiquetas a predecir, esto es gracias a que los datos se encuentran estandarizados, estan valanceadas las muestras, los hiperparametros son optimos y el modelo es muy potente</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="introduc.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introducción</p>
      </div>
    </a>
    <a class="right-next"
       href="punto3.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Caso no separable general</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">2</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-no-separable">Caso no Separable</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#puntos-en-la-frontera-o-fuera-del-margen-en-el-lado-correcto-del-clasificador">1. Puntos en la frontera o fuera del margen en el lado correcto del clasificador:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#puntos-en-el-lado-correcto-del-clasificador-pero-dentro-del-margen">2. Puntos en el lado correcto del clasificador, pero dentro del margen:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#puntos-que-se-encuentran-en-el-lugar-equivocado-del-clasificador">3. Puntos que se encuentran en el lugar equivocado del clasificador:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graficamente">Graficamente:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#derivacion-del-lagrangiano">Derivación del Lagrangiano</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-a-un-problema-de-optimizacion">Aplicación a un Problema de Optimización</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-en-optimizacion-de-svm">Ejemplo en Optimización de SVM</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#formulacion-del-problema-dual-de-svm-no-separable">Formulación del Problema Dual de SVM No Separable</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-de-las-condiciones-kkt">Aplicación de las Condiciones KKT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#condiciones-de-estacionariedad">Condiciones de Estacionariedad:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#condiciones-de-complementariedad">Condiciones de Complementariedad:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#condiciones-de-holgura-primal-y-dual">Condiciones de Holgura Primal y Dual:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#formulacion-del-problema-dual">Formulación del Problema Dual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion-del-modelo">Implementación del modelo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocesamiento">Preprocesamiento</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manual">Manual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#auto">Auto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusión</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>