{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Proyecto Final Optimización: SVM**\n",
        "Por: Shadia Jaafar"
      ],
      "metadata": {
        "id": "lT7huHBwEr09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción"
      ],
      "metadata": {
        "id": "iAcCWzg-tkS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine (SVM) es un algoritmo de aprendizaje supervisado usado para resolver problemas de clasificación y regresión. El objetivo es encontrar un hiperplano que maximice el margen de separación entre dos clases de datos.\n",
        "\n",
        "En este trabajo se abordarán problemas de clasificación binaria usando el conjunto de datos *Iris* de la librería *sklearn*, este datset contiene las medidas de longitud y ancho de pétalos y sépalos de tres especies de flores. Además, el proyecto SVM tiene como objetivo analizar los problemas primal y dual de las máquinas de vectores de soporte para el caso separable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "78SP1EO_pv41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![svm-all.webp](data:image/webp;base64,UklGRqwoAABXRUJQVlA4TKAoAAAv1sFkEGpR3LaNY+4/9vX6jogJyF+yAllEBwNkpXJFdmfNhhbdW3VF1tJhxmfjnf5vtS0pL9OOu7vD+ODu7jLuM73Xadzd3Z3bfda5uLtDRE2EhxSRu9N9z3rXuXcmO1Vn72Xvu9613oX+qiNkXHB3t7hvMRrfDGfcJ8Pdna6XrpviMJbhvotyd3d396jt4PbDvYtoSlPcJXNZuLu7+/hMeHDGDu5umcPG7eD9B+DurrcODpk7f4BmLiO75qY4RBPh0PAfEJ0I7Rq9ERa6S+TuLtHGIZXIYQTXE+Fu8fhMhO6qybpOcgdJuRfpOliqYxuJiV1jd3d3d/czkuFadG0LIAA2N7a52badbK6tyZjatf0A29ps27bGnm4xPuFR2rbteCRdraSquse2bdu2zVWvxrZWtu3Wbuxp1yTffT1vxvb8kJKAbduxNYdt27ZtG2Ou2VuYlW1ryLbtOfxrzDZ+Iz60aNsKGknnAqZNk0mvVSbeC2qt8Y9qtW3P5AYp55yzhHLOOeecnHPOOeecc84555xzzjnnnDaU4Plnvhn/31OGmUUNtwO/aI+xOzCT2EAntB0YviVMG65DcDoYtlzMieVsuMdwoNvQURU2NXQDOsu8PQg7MVPThW5BTGc6MNw2DF2KqZnF5A58BBcaGkrbhVm2pxX/zEfIVCph29jjCpYZi/1ODRgaTheqRUzHSHDOdrEVODdguBVIoQWAAJxk27Z9yU5mvHdN/W5G9ZbMZlfbW1q1betDDACAQJNta7Zt27Zt27Zt21629VT/IbltJEmyo/eeuTOj0A+AqKqt9J8tNwKBaESFgJVgMR9NIQglgNpouiRAYk0+mi4Ra6PpEisW0XSJWBtJlymLaLpErI2gy0i6qEUkWCJoxJ+ZQtRc5GumQOCfEoMUphAtF4WCTbpVKGypQmhJoBJReVUC/IAEIa8aSZsBkYBEgCFYqCdQFg8CL0wDAR1BLgGCQAaAgIOgk+CNlFI/VkQcKwGxRjRSnks+BbPKopzyqgRYxK9GggGCKBBOBAZ4ZJ06bUuySirwtUiAJsgjYPb4OULgAP7UxBGnVbEkCJxVVlKpJzjEcwUCTU9MBp0KgQCBKYEQAZlPFhXLCkkrf3KRI4bLIdiaDMOyLQT5EycoJ3D3Q9mWTogTl1qghiA65ZOA6UMCBoIUAgV/dJx4dlYMkD5NhsAcWJa3qp0Wf2aVPbIOyfXSCwAwKW9FwEagRSC2LdtCwEVwgaCrjjcWq5zGtERSlp7uIUibjFsIKAnIbQqB97MRFBB8fJzHeRyCpLoIkm6Z+YAmGCXDyze3OwiYCDIIjG3eFQENwYv6DhEltDRLqFLKKKHuyyu6qwRZ33Nb4FAiCUaVoZKaFriV+0ogV0tAa1cIXhFQRRCMLFep8tCBQH8y7urPEGjYPiTgiR5NeQNmI7uUVWWVjZcOHqrVVUcOShuKGTmmbKAFY9RpuS8/QGDkpnZ4GLsSPSitadJcULaiuVhaxMGtXFUgcHnQb7UrUQOjsqGJVg4yc6yXZPGSeTjWhyEovhx79xUtMNJTOcvMLvDcgeC6tUf6oH7ntggMCcTtilRTDrL1AoVHjHyg3MjMcgbJc2ol4CYomlVdFcE2wRMCCrsi0aR13CpB99qD1RNmFaLcySiZnv8IBIIEVRX1rQhuEAQRBBM0EFx8hJ+wf1KeWRuw65jQATp6vRQz05VbGRkGHvQhKf0IqAFgvgQdBN8JPHaPIPJvYPcIbs7KLg+R56YENXFcgqL1ArVrzCxT7mXkQw/12Wx+Yt6KQGT34HII8gk4X5dgbCrbYpuHyDJrCeYSjOo41nHqupT3C5OZncqLjMoL2OQh50rwniCMoP+g7hlSKoH8PacWSaYYUjo2dPQU47UOUmMJYl2VETYSNcoP5U1GZeuhEOjazsch+E+QQCAMqZVAj6BpVinvqlaSKYbVBF8kreNNY+OFpp1pWWkYZUF5xEhsy0ZawEJvRUD/Vg5VprsV47YOJWj9Io0T1BHsWErTmiZKeZaRSyPqO3EPXI/dJ7xdlfHQsvXexRMshocDRvFQLGTkeIsWs3rq4KbKOKCDXkdJrGNEB6ctRrmv2MjMbvBQCFJdVDkHetcRs9bgADuMEqJYyawqwLue7wMsVaJJ/00x8l37ZDPTFDuZVaYXCCxTn7yO1CrRtH6RRh2E5jB3iZmliqXMWhh47pBaJZrWOjIadeBL4LXqoOwRMmkXbFErmGjVodjKqHvkpRBsPmMKW1UHEk2NjpJYB6oEbq0f90X/xrm06GtRWn1XrGXUeYN7PaOEHwW/9mDV0RTr2CuGccpT4ETLVKc5r9jLKHbgRZORbXTExzpWiqGZfKoEduBEWbEaveKAkTijaHvrINnUlCBi0juuoz/Wsd0cuuCEWXNXfGTkcmlKeC4yvRrWFvw6Psc6FiYNTpjVPcVLRk60aMTq6Y+yTe86hnT8PWZwwsi3ip+Mqgc8icBOroEd33Fwwsg0xVNGqfRUCc4mI8Wk1w5cT5EGdzKyVPGVkVngrYPcki7BjX4AJq3jTxzrGC+GvBu2sB8ZadWueMvMcE+FQEluKUaQjpOdm8unXV1codMogb4zLWoiNL8p/irLR+BFckuPENcxG7+Tjjs6Dkrgk9ah/hdxb83A60RpqtOcU35QWeXtCYJyAgcBV4driYvxRQcLgA6Jv4h1PHSgtFjRRCp/yCj2HjvI7F/p5zvi0yiBKgCUICnWUWmPWV1WfhGtcEbqeCo3J7XdxnEasY6h3pNM3hYz7yr/yCgrRiUp5asBAPbjNGId88V4MPlf2bliqNhh5hvlFX/mA7xOqX5cZds6vZRerTHKZGnfsXnirKT2SL3pTTCeoI5VHV3NoQwWCPyrzExVnlnPZnmBpfkRdZBzPJ5aY5Re8NhBZmOQ6U1wgjpugk1F7OnZu8EzpxI1l1pP3O5ut3ZSVwx5D/Ol1hhZ5a0QzM1KRkl3Tn0lHS9LUL62YLJSxaLyEb5riZpY1cW07G4jQ8UxMhu8KKUSRBMg5ZLOF1qCAWv4zLayu6H46iIO9Mp8lN8WUmkyNRfSqDVGRoA3TQZGfJF/IpO0fpHGxmIkOF6AqLtRY9PzP2bidLuzJ6xCfJlm00ntZZ9GzPyXt6yAje2yWjWqAI8d3g3HWi+R6KDSUdDo4rCt0mK5mWcWIzfi93nAqvQ43IYSaFI151Mxr2Ndi7qETrUxaj7gRRUVv1Ymm6fcuQvtDA6U1l1WzLSTy0pClDmDtH/A2eTMTC2LvXsOasQVFa/oVWWQzmlIUU/gToMDRt1dxQ59S0cOaitzO2dLmdLefEK9mIlvlTruz2d9kSlXAamXQHQI62juCQLgRpWPYtZeK8WyPOkiIo+NVayZK0YDKXCrP6n/2isaKxIsyh+ftg8f0RwaNjjYZDY/RhvaWcSoDyMb9Tyq1SzPb3AVi+dRsqo1c9Jokt3L9V3qB/zqV5U+fmo+Ogg6zNzVoV11MigWxK9kQasqrBtLK80+r1fFkzwe/JFajzMugTu4ssls6lImtWrCd3Thx3QyoS5taFZL7BDDfpxGvGs6cPEDvN6ags7JJnc9dNYfRtU5n36K3N1dfL/OH8sbI3OklT7+5hF0IOOkGnWsPYAOazvKGqlu+ukv56sVC6wzayfvwd6NPmJ5NapIaW0AoEew6XjeOEEd6Nj+RF5lNQua+4qNVjBHHpvy0b6eWGaNEiiZpNcSNOlx6KAHi3ToHP8+fFpzCBbD/p7AilldUqzkfModPoU6io1guTWKr1yi48l8iqH5HTdu5bF1LM9tv8EqAtWq0ryjGOr2iVRSgJtFWcvaPPpkjJEOUsl4HkHHztvZNH182GE1h5FN+EGAxNW/9zpgiXUyNaPIG8qi9CNaxrSEmEkwKl2JpHcdcVcQxzZTGt+rBI06Qjvb22SmCg9nUebSS4aubZ1DMXPVaCQlj+igH+epfNhnTroZhMCinqCYZl71oCALLOXHPJUGUrKVYx6rzApBG3JIZLefmo+OPHCjLgfPaGFgk/VQG7N7VPlEYys5Ed9cziQbWzEZErmXB5ZSs+qTyxdyQ891Qpt68vMf6/b6w6A8s5Gd8gJjI4LDiMjslTVH+WklnQyJCGBJpaVGbimrqdCcUQw0uCN13MJhHTE7uNCP8ddGBtnPoRBlLw+Ryu3hs8hYWo0Ml0HS/+YWszKnZV8pRoUmUHERLfOpxAG0iT1BQknp1Brel3cz8pEMNmkdL3V8tTsxvK1N3rh/F/krVrJ5yHusf2ZezizNpUfAZKPb3HpZXo3KG2SQZuDtTcdRn24qARJX4Y65oJjpL6/hykYlIwRMVvItS8snGMVOEl+oBI8ai9FnTUBsw48l37EnbNbZxaDY6VYvPbep/RGvxD4tZDK9Ie9m5vI1gASig15H8l2kf623Cd6FBcfwg+lEOEf/aTQdj2uOydJi5sSpggTyfjqK40YdrWsDkaNtPMLWDhAUJivr4rjGLJOlxax6yhuxAshgU4xrjXGsY78EL3RMH1ZzGNlT3iQdrVqOm+EMON34P109t76/IZislFlVAkggfdwT/NR8DmsbdiCOYx0l72VHzw0EafVZMaxrWptcreHwGYnJZpUFMkiPkOltB0rg37kYTjqOjnA8R9gYf0dziNnQoqEKzWmVAquJcNrrzEBMNuoiQAp5nD9ojK9uLsXoPKwjSJfA5hH6sU6WqhrBz68709xT7PBlWsSIpt0Qz4zDZKMEyOJR8OliWOiYinettym8ut2rZggmGb/+/7EhOjOjMFkZxUciT27Qee93II4H7NM2/Bj0im2hiekeGgcZ3UCYbCT+gOXynBX3pCPkV/oaD/vw4/mZtMVdga2utBi5corSeSqSHddBz94mB4+luI6Yo/0KgsJkIyeNShICFQKF+UNl10DhjZ3rzCAoRbOwjWLEgJjOB3kTBITJ5/+GEKgQXMblAawuIL6A48JjCkbK+5uWZotipMHH4fowDqSdXTEWk82sAghUZoYrDYiTehQMxIet+kbAKJ8Zjid0jaY5dF91GQMSk83MhoDlXI8rTtVxnWvgka/awI+eM6D5n9lU1Y8nU1NbNCnVmkm5bX8vYiZ/huInMyMgaLmx1QVYuIAbC7zagEu8ZbcjxXQW8ro2NUdNkURTabCCMLmsCoDABWOrMODINOCgVmwDWe8O2YdB/+tSetHvPV0bHLePx7/FTOZ7UIhsNozDj/Vtxdg8V5omrqW0JpJOIURhspn47YckCZ2WpkI0Ukno6jNhE37cHvXZR4K7V4dHH+IDhMm0rO4ZJFkB37EV8YvGE43hbeWzG81EJjbZuqL5ZlKIBJc0PjGLjjWs6BhMpok4d0hh1S2mTLBII7Qr4gNiikw2/TLNj4yOrRz41vBQ9zdsUreOweSrsZ57RCO9Js25nMajBO92DOR0K7jysE1rMS0tzYpdpLWoUVZqEZN9cIaKFdTxavyTYLcmee004ovEpWMAIKFB9blSv1aP3yNLyyfFQ2aZ7IfzU2g027oEY9sWMTV39gnlGMQE015AnmAAl2DDLnjFBTGTQX6doq0mUUWaJqyIAbPGwpzG9SLNOIAJpH32fAMuwNjZZ1lGo7pWMwFhslEFgrM+dua5++5B1IIXDg47IMIPy3TGCZSLBoXJqqz4ghv14FtuTTpyGkeGq3EFLkGUh50JsxkYfA6FvaLgToKAMPk1W6YDOJHQ6fcgpsl+3RsIaqwuMpKSwYbmi7k3KVbqon3gNA0Gk1+INtQDJzQ6aETNIKFsAABABleXZqJiJOeyZobo79odQ0yCwWSaP2lDaXCgY0Lczz6nsWE4RqxJZLAbrT4oRvw6nwHSZtB6BkkXLcGHEYjJNPsfGpwYpm8Zivgxp7HwYyGJ9PllgpSlO7gfD62aFDN9rRG51rHRQc7lZ884TKZZAzZadVPklvz5YxPiMxyLaSGo4JFfCZ1uVeFiLNgMx2xA928eEBN9vYuIfn8Chcm05IIN7TWVrKkmmw+HICM48+n8iPH/qxkx1O56R39wWMLtCRp5TicBYTItUbb++NFy961RKWjwcX4VKOEH88PfazS2kiN8T6spupu+n+coGwiTaQaBDRf39DmN/3sQRY30RWLfNvgIzLFfAlf78IPBlQfHUEhd7RUE/eBEYXKbQa3YdsQh89D46xwu7unbaYyZauARmDM1aHUjxSYzfLCdMxfRsE4gTG729J1HiAUrx5zgt9zTHXPKU8HXBOW8KprPFXP9/dsrE6m8HYPJQ7z0eLxthQTvtruB10g+1YORKIAcNjQTFA+FOzGYvNwXHH1gX6Fjrxd3DseQ02RIIx+ADK4uZGj5IPCo7qad+Hy4yyEzfxOgKsFeCUNpjf9yRWy5OJDCbgQfcSGnrYUXeFSXltrypsgIWDPgQNsipiYjLRn0y1WIbbgAwmRa8sCNhmgRxS5DAOI1q3J39J6g4QcPQJhMMxrs0Ejfa6+fAS4lZzMeR5sMP9iDwuTqpdqzz7Dl476I0QMBFImVxt1cTuOmRuuOjkjckXq0cuvxmbtOuVQQJrex/icTfJQ7+1vqwTcCGhFnr3F6Bi4mwUnckXo0rys+wmBys6fvPEbcI0v4rKna3H0nGKFxTaN6Mq7UODewHVJ37A/NZ5yqmMl8ww/byW85jV0r6EdGgPPQ1GBO40NbpO1IvUKGlniBbfKmn/riT7fD+/+w4BBAa0R2r3QBQJPAXII5EtgUsLuRY4eb8P97IK5NpjlAkzPvEH4cs8bJXH8DQ0dN4nPPEj6rw9Umm1XtxYCjBu4vN4NH2y6NJxrHvz0suglexbXJZpUHblSkqWhczt23xuwidXN4VjBJn1+uxP+vFtYmZ5d0+55T4E4/dN9bl1D+AC6RqSP1zDrjtXj8drS4Nrm6m2E9AhIEONDRMlBfpFkUybWpBjVBklTPluaxuDa5DeIegT1T3asEG20GisIEQfcCSvO6wDa52dN3HTvXtkV81q6dpl6GESLus1dmaPVUYJtMc2Mhp689bGOTLacvOOJ27e6zbRghoMMuYLcj+iSBbTLNXzRl86MFJ+3N9PZqqhBGiJeHFRDPU1ybTKtBs8YFdloBkRmmbxkgRcM3yd4RQAqaILfJtNSVN0Vuu9v9pSO1TTzkb3VlRRXXJi/N3n2n82DHFWvq+689vh3y182sya/xQzetVwtrk7PdDu8TsdaWFfE7zR+1u3g3SJtfppURLVv8bTLX8INg0KZpq6mACWi8qKn3OY1+bJCjI/Voupp5xN8m+yT8aH+l7XIV0ridYPn0uzcUaxvkBEY+ncnQck1gm2zm4WIu2KzPIfzo74f2qoh9M8glpRFzGAFOUIwmVdZ0M6xHENgmm7lB0xBGC47SqLMbGicSfPF0Mxhzx4DEz/lVoNtkWn6blZzlQ/+Yz/TjhqfxWzkHjSvHkHIyoIDEJ/mVb6u4NpmWIbNvuSGVg9Q4uRfzuCUrbY9B41ZCpxDwBMK8qjqeNvn7uNvkpmXcd9DyYi/ciAPA0uyORqKmKlZQJ2TJtKC/BNs0LnWv5OSvKWvAs3r3XPu/jbg2eRFnbLBn8/pt+/x4jYdvuXVFcgEs0uTVcUASqVvdcwN5mr/FtcnZu0YChNUmn6kmt7pXGnOd/hd9kZUzhRRkrtt+09zkb5M5hx+2h/fcrqZCwFHy5pczo6XFheaRuDZZDXrltp9wj4CLZOhIvUxN10Nn4Tfi93kgrk2+SdrIBQrAHGmZ8eju95MQ1iZfSy8NjcBOGqnYnVokhOYnh45NNvO32UAe7GifYPocWIUecnSkXv7AONbX42+Tl/3w4Vtr8tB10mBLf3Ntd2yskKJjf8pbRLEWj932RVyb3LQoczZG4Ts5nZH44w/uYxkhQ0fqfadZDQpskxdxxoZ7SIDI2B2HdwAH2b5ikVBustjc+jPzt8m8ww8rQ/Qj9QRyOY1TCZ3+QB8/1/5kcHV+tPv9wgLb5KXes++IQ/gBCZ2JRnwut3Wayn26j79BCeyWacAN+ey5Y3Ftsvpce5usUWL4ShI0Uu3E2Sd4V1ODuVxOk8r20uaX7X8/CXFt8oH+nMMlOTSub52m4oZnBdMkv36u56HJ/RnkNPWpewOecE63mL9n7+GHsDaZ5hatjMCe9ns1g9x/F6nLRcz6+IFgRxN8/BoQfmCcWXu0ycKO6qoVve3SnfV592kdcNSDJ5i0dbn/ntiZroDv2MIxi0bfMK3/B0/Vnae4Nnnwa3dA4TuBC/3imeZy7cYcjmDvg8dx++La5KbzwgPLgBt11Gg40ittH974xmubNS5aBgW2yYs4c8P9ZPjhUlPtCOGNP5Kx/GivwswpgW3yMu07eAyzefAgqWvyDbgWj9+GFNgm03wGtXnwgsytzjTgIJdvc7YRv88DYW2yem3wKonq5i78ENcm03JCKzdggaz5ZYIlHEWTsDY5ccM5+BH88KY9SAV+S7fW/c1H3q/ArReAsDZZLc+FR6OwIewQWrTKE9gmXyoeWKW0Ut495LSqFdcmNy3KnE1QyfBDUqmcCc0BgW3yGj5wY28y/JBT8iPGNXrwplWBbTKt4pM2OfQQ9HSZ+QZcgDGzTwW2yTSfQ4XCDx5D9X54p5kGHOTyrc+ywtpkNV0IR3hMrPHDO50C/oO4NrmnZ+4+XeOHbwqGkMTjAJ63D3quE+fW/oX7k5bt0GHQJKxNHvJlxxORYDEs8TiA5/GDnuM0V5rRQtrkjflrAazJwzfD3O94ALW8Fx6DQiyEJR4H8Lx+0HOblG5WuSLa5E068gks9/lHAya1wONXOUqGH1LQeB0H4tOM9mLMrBHRJj/6Yi7cHLALPVgsp8DimQv3PwgzAQlODw1ADlZ7/GHjsroKV+fua/8KaZPHjAtrHxi6jyGXy/3wAtsCkKCmAino5vGrgUO3/Ihx/kdPnFSLaJMHwCesqMnyhHhUoYlH9+u1ceWXGYQfYtrkO8b7z6Xq/pHgbmjiMavyupp9ukVQWBF+iGmT547/stTuhuUzD1L4F6wNYQQ4CqjZ03e9GYWoNvmOcaHtDti1VWCo3oPwbvx/FBDNIHFHdQdAxGcJ69U+Hk44qhOuPeGjSvKb4o7qqi9GvI+Ubn8Rqt18LgK+vjCpvgjOw7wEHtVdj7ce/Y0/QLCc4pefEAn+9S+J9P/m2CVgSQHLAbimcSMO/9qzfgs8qrtf5f1OU8hYf6r7B0mkL1xswBoA4jhefADiENbuCOKO6p6Ew3eQJHJUOO6KumaAxQRgt4AuADiAqKO6NBPBVtLICeM1xXG8JADsDrDKgGvCOxZzVLd6nV5+MB2klFqcZpxsLiCeJs5dyFHdNlhTJ61NqioaAW2y6unZe86cLw0qlatT+Odx4wAC2uQhX3YCEbEAcgq8U2q3f+6AYxbQJq/f+0+tJKukUsD5HTlGsvjlw3t08WwyrT5tcZMCBQJTkFTCENfg3uthzJjUmB9dPJtsZMumtZgWAEIdP58FKuwebGOZkyagTaZZCBD2+PicbWeCT14t7CTk7Pq8/UQxhD8+PsPihn/9quUSbt6VlBV2EnJ1N8N7xJq68Me/50PdfjPx/Ed1Of9+EuGPb89ebBRf/qO6vKsE4M9zjWegrAoQeFR34/9798C3Nnlm3Vq1sktjKPzbi51ZqDcFXNKteyAEHtWlOV1WKRd8Wo8Jl9AVMDTvQ67vs8JjCvHVBcTzFHdUd396biAI4NPHuBxeglxSL4MzC5luYvx+Ek+6L/xt8rZtVpN04Fcu9qxyqTqriw1rv1xbUcW1yWv80E394F/9bd8W+v7bsE631vnVB9WHsH4nbLWwNjl71zUZ/4I5qzAw8ZtO0Sgr3G0y1/AD3ykvRBPOGMV+b4W3ySKsDmHqwCg+Atvkpq6GzMRbwg8BuoUvlTWLt26nbwLbZFr2f3S0dmP18uOXAQLTJtOcKaup+Cm/Cot0y19VXJtM80urvhUU6HMgdHlJkW1y01o+ecdYef/T+e1bWypY+TsvF120uZti2ohrkxdp5ob7WOm3fWyZwGhS8l3522TOlwb1myOWCFr1jfZHc7fJvMMP3+VXskAm37JmZyROYJvc9dBZhBSbLKVNpmaQy7cZFtgmq9LqUiYl/JC21d4vDSqsTaa5X1qz8Gl+FQ4Euk02crasTtWv+ZUMUFlRxbXJ+vP3TreqE/JBkuU2v5KCZpFmbYQU1yY3LercTdBY8OknghTQohGrmd0C2+R7QQJExnH75vP9LSecqpnj3G0yz9rdiD6pIvxwsc1z2duWEPJ5o2jTXBLXJqsFGr8KEt8p72qb5+GN5YNMw0JMXfMnTSxnm/xkXKuZdzJn4nKb55FkhT7uLg0qrk1WN+t+m5eJhmv4IaxNptXBQ3nY5mVidfDaZLV+7z+11qKoednm5a/b4NfttHCe4trkxVu3IxoLXrZ56fPLRqkQ1yY37TQeWIbXNs8uyQrxOVS9JItRujnb5F/lYZOtp77YiN/nwSLN2vAACRAZL9u81M14zOdv2KzGRLyAjuVENQs8YVUsZvNetmCpm5+cb5i/0ePTm3n6q2Vu9c1SbTLPyyI9IQ5I0JkHT5K4owkyDbi4y7Y+nTNnm8ztskisTgYvE0fqcQg/eNtk318WSdKO1KtLhh+cbTLPyyIto4fBcqEVOW2WaMtuCEFt8tzxX3KL6RTAZ0m9LJKUrjarDFFt8h3jYjgeFtZegF2bA8vuBWDQSFu3GfnCJvNaPT+mAf7k8pkHTC6LJGV+OV/e78z9Cjyqu+BT1sBhVyZgWT0DnruJc6SeXc4VDuRH3M2w3p9NO/nFJHebzJM3OrSvtrkskhCfA+w+L8KAfAP+/0b8Pg/EHdU18q3dRbf657r1s/zWZvftHvxkGnCQy7Y+yQo7qqvM6p7dZZF4b/0M97HZ7YsHPnXJ8EPYUd1qs+bup31ndo6YnXMO/mZwa3f4NgrbevS9H4ty3MO/GZc3XPhVDbrVVUO5/MRDfEk/OV12+RW7nCvw2Sllq50vXSQLRVRq9ll974IF2frUYa4s5h7XbzC3umr5LjoOg1jwUy4V0g27W+mTPAx5T6oIdMoI1Liz+Xvfvhfn+Mfc7877pBxpIm3axbU+f4yATFZNi7d+JwweWKWvUmSpWJ13cSt9GvVH3nPPPff0LlRsPcpkhiBv58pi1uoJ3uf2/XpH1gpX2B909xWRycuy/9A1PLCMv1JkmehWNYjB06c29fjnvcqR5XdNfmhI2hhcogBIkUoHQc5+L2s6FJMzg541hTLFXGXVNr/51/X4/zfjMXmi+Xeq81mKLA9+OT9inL/REydZZ054wk0aDLsnMFc2a9szx2zS7otvGl5xz/QlP3UbHNuo2RW40YnNBr0R91Ro9PoFjslmpvkwRWZ1pB7DM0MFHDzCj3x5nHvy53FajieMPZVrmou+axdY35suFvfMVicPW4zGLb1trEevXt3RmHxGPkyt3G3pXOdDBjd51+HHVAurAxfc2Mc1u4OmXljNpv3l2d6ZEknV2v1PfMrDY7JR7vs6Rbb/XuY5eznAm8VduuWQ2/DjusAz30r53I+KkvUuc6/qZNP6/TO9V6rBNVcWc7erV2hMboMEqf5OkW2/570eaxBOTEx5irSOefCbL5ezzPZxFrTHqS9FaEweyhUnHDnZZB+myF3oY+32yr0eGRRKnJHyqH3uPPRc59AK6lZXqeW7+Fisi/DDd063K+Ng56G9HscXPuTByHTlWducPrrnNdSt7jCuOXULD6zS7/lVl8bPQrupGnATj35aoxhonYMrPftgbnXN7FyRmy8SfCcX4Yf/UuSwXl2FeNyKhULy5rJ/QdzqfqMQaXOXxjBh2M19+MFGd5esc/mDGY3JZqZzzq/Yvb9w9stMZ2Dc0heNyVmzCuE9ksvu/XlLssIr3Vr8DTuXDHLZVidZxU5jT+UOQmNyFefZT37JucIqizZr7ortDIxB/1nAZF9ea8VvKbL37+9wGjk6ZMVafW/BYfJQrjjxyINN5pEic94fCKVxXjPfKtYox5coTF7x2y9DMqn+SJH9dHaaIKV3xUG/vBCCwWQjx9b2hftU3qmS1zbqwzNDhcMcKj/cSp8+6WJwax9cQWByvz03YGa/jXrd5qWiKe9HRqN0KE7a+vRhxZV+AEw2spzHNup1C5aJ1SOsiZyCYggak+f8FgAgUhOO3bjdSh8sJld3O7xHtNhkcVaHol/mdyt9QJnMvpvYZ4ayy7kCDaO4cz9mFvwmxOwnzqlagGGUewIfM7s6d11DQiz4cL6UeEfGBxZmvhH4mFlaLW7Yl8+ZEyAKEDTikowFFdNQvEBgspljpUUcgkg8nHNAQUuJYgfeVtfMrl3l+SEtws4Yy5wrkNjCFjNegrg2eSN+nwebePSTOsF2qHi800BvWqXwKYhrk7OvWSXaDhWPdxrkq3tJYZqzfG3ymWRyDz94/34SYsSSgd7tdGkeCGyThduh4vFOg90vP5SYNrnaB78klfhDfgGYbr2SiDbZSGxZZZu0yUHfBGAWbeYd8Wzy8V5DcIQVITft3MzXotnk67H+D+QPvm6BD5glRSib3LRpJ77ovzqwKPj8cvADtBSLZJMXedZGByMGP4jvAJ6MlV+AA0a2sbbJfrk0KEBgfl4EOOVJb+RXQWxydbfD+0R8J4camN/uwQ20qhOi1YyoNjko98UDHLj7gQWwycqovAka3f2mloHonIMcKK2z8L9N/gSjZgduFYQ5V6ADY/K7Tf7oVkUbAEDCG4DSvONvm7xpJ7/8OaKUSJ0cI8urHWRWr3xsk5sWbd6mmC4HT5/KW5Hjbk6iVbJ/bfIiz94IiQSIOrBKiv2yo2gWebLJPg8/Am42VQgANFt9aZPnnBJ+BLlCgc1N+tn40SYbJWCP9ghA9oFWfSs4kO9ssjocAIgAwDHvis9sMk3cAUNEAH7UVzZZbcbpL9dOESIDYOZFP9nkxduwE7ab4b2/+QgBlOZt39jkpkWftykGDywTJYDS8srWJvMOPzIQKQCaSUqtUw+DD2xydyPGSJjNQ8QAelXqRLjb5Dnt0TvlIXIA26bUanU93CXfOl6oUAThuWn5rLjfYsCIAmzrznBlM88sJmw/RBagrFLeFY4M8ZLjcPM/ZnwmH2EAM8342eTF27AzFg8sE2UAs1zgVRd9/ibYZI00gFlu8amLPHtjJGYzEHEAWr3kchc79iibh8gD/BOXu9iRhwgEGFnI5S52RCKAVs1se5QVX4hOlLeYllafGDLUK086md+R41v5CAXs3vkzY4iXHI9DHG2UAnqplGnuMvpri79hZ2zSJkcqoEWa0Txjwskka8QCzNp5FphZXZvNQOQCzOomk7vYkYcIBtB8weQudkQygGai17vYEd0Amh+9QNMPohxAS7NraCHSyhGiHQ9GyyeX0FyjNT2IeEDLGj/Nf+5upQ8tMhD5gLJUornj5lb6zAQiIGAWU5qnjpxjeVNkEAkBs5x34toBIiJQWm463cWO6Ajcih00gyG6wPfW0dDKHyIMPO9glZlEWjlB1ASetwKa67SRPkRPNqmPaGiOKppTDwsRFGiZfF8zE4ikQHn3kINEUsgHCSCV1NTnIylAsIQVD6IoBcTkg+gJTAFTH/gJgoHaSKCfQfTZg9oRY8TQFOp8U8JB9fW19RXrU//k/Eq17t+P8yvVWl7J3dvy8r7c/yO8/qPrHd6BtTmw2jxES00hmj6Cgs2jqLmMpo+gkPIoipKHqKqt9J8ggsAL00BAR5CbnRVMHLETAUd0JOW55FMEBjitDkc28Si5mBYeWSfL6048Ui6Srz0tSDKr7JF1iJaLTtuSZFs6YTpK1m3phDjxlC93PLIOEbPjxCt6wsSjY0+bL/Lk+mlhdlYQMV8r9S8gYvLhVlQsAA==)"
      ],
      "metadata": {
        "id": "Xy_8OMvnADwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, se resolverán el problema primal y dual para clasificar las especies de flores Setosa y Versicolor. Posteriormente, se repetirán los pasos anteriores para clasificar las especies Versicolor y Virgínica. \\\\\n",
        "\n",
        "Para resolver el problema primal usaremos la función *Problem* de la librería *cvxpy*.\n",
        "\n"
      ],
      "metadata": {
        "id": "sjxkNSeLyxp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las librerías que se utilizaron para la realización de este trabajo fueron las siguientes:"
      ],
      "metadata": {
        "id": "SUdPVHUnzdZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías"
      ],
      "metadata": {
        "id": "hl-BkGBeExdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize, LinearConstraint\n",
        "import scipy.io"
      ],
      "metadata": {
        "id": "UP8tO1tNbh9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conjunto de datos utilizado"
      ],
      "metadata": {
        "id": "VPvSp6RvE1N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data # Variables explicativas\n",
        "y = iris.target # Variable Respuesta"
      ],
      "metadata": {
        "id": "ZsScyqgoEE2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desarrollo"
      ],
      "metadata": {
        "id": "n7nPn6Fm0bwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iniciemos escribiendo las funciones objetivos a minimizar."
      ],
      "metadata": {
        "id": "NuOFZfBx0f21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problema Primal de SVM\n",
        "$min_{w, b} \\frac{1}{2} |||w||^2$\n",
        "\n",
        "Sujeto a: $y_i(w^Tx_i + b) \\geq 1$ $\\forall i = 1, \\cdots, n$\n"
      ],
      "metadata": {
        "id": "xmI2FwGXSMGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problema Dual de SVM\n",
        "$\\min \\frac{1}{2} \\alpha^t\\hat{p}\\alpha - e^t\\alpha$\n",
        "\n",
        "$p_{ij} = y_iy_jx_i^tx_j$, $ \\quad e = \\begin{equation*}\n",
        "\\begin{pmatrix}\n",
        "1\\\\\n",
        "1\\\\\n",
        "\\vdots \\\\\n",
        "1\n",
        "\\end{pmatrix}\n",
        "\\end{equation*}$,\n",
        "$\\quad y=\\begin{equation*}\n",
        "\\begin{pmatrix}\n",
        "y_1\\\\\n",
        "y_2\\\\\n",
        "\\vdots \\\\\n",
        "y_n\n",
        "\\end{pmatrix}\n",
        "\\end{equation*}$"
      ],
      "metadata": {
        "id": "04IRGOEwSoch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Caso Separable:** Clasificación Setosa y Versicolor"
      ],
      "metadata": {
        "id": "qdcP_cZPLX9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar las clases setosa (0) y versicolor (1)\n",
        "X_subset = X[y != 2]\n",
        "y_subset = y[y != 2]\n",
        "\n",
        "# Cambiar las etiquetas a {-1, 1} setosa = -1, versicolor = 1\n",
        "y_subset = 2 * y_subset - 1"
      ],
      "metadata": {
        "id": "kpA4KQ4QLh3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problema primal\n"
      ],
      "metadata": {
        "id": "0X7SvbrmA6uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = cp.Variable(X_subset.shape[1])\n",
        "b = cp.Variable()\n",
        "\n",
        "# Restricciones\n",
        "constraints = [y_subset[i] * (X_subset[i] @ w + b) >= 1 for i in range(len(y_subset))]\n",
        "\n",
        "# Función objetivo\n",
        "objective = cp.Minimize(0.5 * cp.norm(w)**2)\n",
        "\n",
        "# Problema de optimización\n",
        "problem = cp.Problem(objective, constraints)\n",
        "\n",
        "# Resolver el problema\n",
        "problem.solve()\n",
        "\n",
        "# Obtener los valores óptimos\n",
        "w_optimal = w.value\n",
        "b_optimal = b.value\n",
        "\n",
        "print(\"Vector óptimo (w):\", w_optimal)\n",
        "print(\"Intercepto (b):\", b_optimal)\n",
        "print(\"Valor de la función objetivo\")\n",
        "valor = (0.5 * cp.norm(w_optimal)**2).value\n",
        "print(valor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpSYZpM4-75x",
        "outputId": "f0907a2c-8830-424e-f71e-a04508e0a819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector óptimo (w): [ 0.04603438 -0.52172249  1.00316436  0.46418056]\n",
            "Intercepto (b): -1.4505608374882162\n",
            "Valor de la función objetivo\n",
            "0.7480579265182639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí podemos observar los coeficientes que describen el hiperplano separador de las dos clases. Además, el valor de la función objetivo cuando se evalúan los valores óptimos."
      ],
      "metadata": {
        "id": "pb9_avUo3wOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problema Dual\n",
        "Para hallar la solución del problema dual se requirió del uso de la función *quadprog* del lenguaje de programación MATLAB. A continuación se presenta el código utilizado y el respectivo output."
      ],
      "metadata": {
        "id": "Y9GGYkiv3Gbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```matlab\n",
        "% Dataset Iris\n",
        "load fisheriris;\n",
        "\n",
        "% Convertir a numeros las categorias\n",
        "y = double(categorical(species));\n",
        "\n",
        "% Seleccionar versicolor y Virginica\n",
        "indices = (y == 2 | y == 3);\n",
        "X_subset = meas(indices, :);\n",
        "y_subset = y(indices);\n",
        "\n",
        "y_subset(y_subset == 1) = -1; %versicolor\n",
        "y_subset(y_subset == 2) = 1; %virginica\n",
        "\n",
        "%Problema Dual------------------------------------------------------------\n",
        "%min 0.5*alpha^t*p*alpha - e*alpha\n",
        "%s.a y^t*alpha = 0; alpha>=0\n",
        "\n",
        "% Matriz pij = y_iy_jx_ix_j\n",
        "H = zeros(length(y_subset));\n",
        "for i = 1:length(y_subset)\n",
        "    for j = 1:length(y_subset)\n",
        "        H(i, j) = y_subset(i) * y_subset(j) * dot(X_subset(i, :), X_subset(j, :));\n",
        "    end\n",
        "end\n",
        "\n",
        "f = -ones(length(y_subset), 1); %-e\n",
        "\n",
        "Aeq = y_subset'; %y^t\n",
        "beq = 0; %restricciones de igualdad\n",
        "lb = zeros(length(y_subset), 1); %restricciones de desigualdad\n",
        "\n",
        "% Resolver el problema cuadrático\n",
        "options = optimoptions('quadprog', 'Algorithm', 'interior-point-convex');\n",
        "alpha_optimal = quadprog(H, f, [], [], Aeq, beq, lb, [], [], options);\n",
        "\n",
        "fprintf('Resultado de la optimización:\\n');\n",
        "fprintf('alpha_optimal = \\n');\n",
        "fprintf('%.15f\\n', alpha_optimal);\n",
        "\n",
        "% Valor de la función objetivo\n",
        "value = 0.5 * alpha_optimal' * H * alpha_optimal + f' * alpha_optimal;\n",
        "fprintf('Valor de la función objetivo = \\n');\n",
        "fprintf('%.15f\\n', value);\n",
        "\n",
        "% Encontrar los alphas mayores que 0\n",
        "indices_alpha_positivos = find(alpha_optimal > 0);\n",
        "fprintf('Valores de alpha mayores que 0:\\n');\n",
        "\n",
        "alpha_optimos = alpha_optimal(indices_alpha_positivos);\n",
        "disp(alpha_optimos);\n",
        "\n",
        "% Vectores de Soporte-------------------------------------------------\n",
        "X_filas_alpha_positivos = X_subset(indices_alpha_positivos, :);\n",
        "\n",
        "fprintf('Vectores de Soporte:\\n');\n",
        "disp(X_filas_alpha_positivos);\n",
        "\n",
        "save('soluciones_2.mat', 'alpha_optimos', 'X_filas_alpha_positivos');\n",
        "\n"
      ],
      "metadata": {
        "id": "ZRFRcyz5otOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Output:\n",
        "\n",
        "alpha_optimos =\n",
        "\n",
        "    0.6713\n",
        "    0.0767\n",
        "    0.7481\n",
        "\n",
        "Vectores de Soporte = \\\\\n",
        "    5.1000    3.3000    1.7000    0.5000 \\\\\n",
        "    4.5000    2.3000    1.3000    0.3000 \\\\\n",
        "    5.1000    2.5000    3.0000    1.1000\n",
        "\n",
        "Valor de la función objetivo = -0.748058\n",
        "```"
      ],
      "metadata": {
        "id": "q-mRnzpj4bJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se hallaron 3 multiplicadores de Lagrange y sus vectores de soporte correspondientes. Por otro lado, el valor de la función primal es aproximadamente igual a menos el valor de la función dual. Esto demustra que hallar la solución del problema dual, es equivalente a hallar la solución del problema primal."
      ],
      "metadata": {
        "id": "KkKQxbeK7q0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Nota:* debido a que los valores obtenidos fueron hallados en MATLAB se recurrió guardar los datos en un archivo y posteriormente cargarlos en Python para implementar los ejercicios siguientes.\n",
        "\n",
        "En este código se muestra el proceso de cargue del archivo y la obtención de los datos."
      ],
      "metadata": {
        "id": "4QM7FniT6EqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mat_data = scipy.io.loadmat('soluciones_1.mat')\n",
        "\n",
        "alpha = mat_data['alpha_optimos']\n",
        "vectores = mat_data['X_filas_alpha_positivos']\n",
        "\n",
        "print(\"Vectores de Soporte\", vectores)\n",
        "print(\"Multiplicadores de Lagrange\", alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYe4ZcK56Kmp",
        "outputId": "d248a810-e4cb-4f0b-9213-46443cf28c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectores de Soporte [[5.1 3.3 1.7 0.5]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [5.1 2.5 3.  1.1]]\n",
            "Multiplicadores de Lagrange [[0.67133404]\n",
            " [0.07672389]\n",
            " [0.74805793]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar Condiciones de Optimalidad KKT"
      ],
      "metadata": {
        "id": "I7hR4ByrGZjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condicion = True\n",
        "\n",
        "for alpha_i, x_i, y_i in zip(alpha, vectores, y_subset):\n",
        "    condiciones_kkt = abs(alpha_i * (y_i * (np.dot(w_optimal, x_i) + b_optimal) - 1))\n",
        "    if condiciones_kkt >= 1e-5:\n",
        "        condicion = False\n",
        "        break\n",
        "\n",
        "# Print message if all conditions are met\n",
        "if condicion:\n",
        "    print(\"Todos los vectores satisfacen las condiciones\")\n",
        "else:\n",
        "    print(\"No todos los vectores satisfacen las condiciones\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4krJ50GGjbg",
        "outputId": "b359b28a-f19c-471d-d598-d4b0890c911d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los vectores satisfacen las condiciones\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error de clasificación"
      ],
      "metadata": {
        "id": "2jg7P_L0Ivq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_values = np.dot(X_test, w_optimal) + b_optimal\n",
        "y_pred = np.sign(decision_values)\n",
        "\n",
        "error_rate = 1 - np.sum(y_pred == y_test) / len(y_test)\n",
        "\n",
        "print(f\"Classification Error Rate: {error_rate:.2%}\")"
      ],
      "metadata": {
        "id": "0YQCJgc1FdKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a01c331-e79d-44bb-975b-f2917faa8ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Error Rate: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que cuando los datos son linealmente separables no hay errores de clasificación y hay pocos vectores de soporte. Además, se cumplen las condiciones de optimalidad KKT."
      ],
      "metadata": {
        "id": "guHy2Gl26zvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Caso No Separable:** Clasificación Versicolor y Virgínica"
      ],
      "metadata": {
        "id": "cvfWn0PkL7J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar las clases versicolor (1) y virginica (2)\n",
        "X_subset = X[y != 0]\n",
        "y_subset = y[y != 0]\n",
        "\n",
        "# Cambiar las etiquetas a {-1, 1}\n",
        "y_subset = 2 * y_subset - 1"
      ],
      "metadata": {
        "id": "G06Qy_ymMEQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problema Primal"
      ],
      "metadata": {
        "id": "MKprw9S1Mx3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = cp.Variable(X_subset.shape[1])\n",
        "b = cp.Variable()\n",
        "\n",
        "# Restricciones\n",
        "constraints = [y_subset[i] * (X_subset[i] @ w + b) >= 1 for i in range(len(y_subset))]\n",
        "\n",
        "# Función objetivo\n",
        "objective = cp.Minimize(0.5 * cp.norm(w)**2)\n",
        "\n",
        "# Problema de optimización\n",
        "problem = cp.Problem(objective, constraints)\n",
        "\n",
        "# Resolver el problema\n",
        "problem.solve()\n",
        "\n",
        "# Obtener los valores óptimos\n",
        "w_optimal = w.value\n",
        "b_optimal = b.value\n",
        "\n",
        "print(\"Vector de pesos óptimo (w):\", w_optimal)\n",
        "print(\"Término de sesgo óptimo (b):\", b_optimal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIWEGISgMW6k",
        "outputId": "4d6c22f2-7edf-4652-bf65-25e9c1ed2bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector de pesos óptimo (w): [-1.84830903e-07 -1.29943970e-07 -8.31403187e-08  8.32640084e-08]\n",
            "Término de sesgo óptimo (b): 3.2808696905290597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problema Dual\n",
        "Al igual que en el caso anterior, se utilizó la función *quadprog* de MATLAB para hallar la solución del problema dual. El código utilizado fue el siguiente."
      ],
      "metadata": {
        "id": "-zHsQiGDM1Na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```matlab\n",
        "% Dataset Iris\n",
        "load fisheriris;\n",
        "\n",
        "% Convertir a numeros las categorias\n",
        "y = double(categorical(species));\n",
        "\n",
        "% Seleccionar versicolor y Virginica\n",
        "indices = (y == 2 | y == 3);\n",
        "X_subset = meas(indices, :);\n",
        "y_subset = y(indices);\n",
        "\n",
        "y_subset(y_subset == 1) = -1; %versicolor\n",
        "y_subset(y_subset == 2) = 1; %virginica\n",
        "\n",
        "%Problema Dual------------------------------------------------------------\n",
        "%min 0.5*alpha^t*p*alpha - e*alpha\n",
        "%s.a y^t*alpha = 0; alpha>=0\n",
        "\n",
        "% Matriz pij = y_iy_jx_ix_j\n",
        "H = zeros(length(y_subset));\n",
        "for i = 1:length(y_subset)\n",
        "    for j = 1:length(y_subset)\n",
        "        H(i, j) = y_subset(i) * y_subset(j) * dot(X_subset(i, :), X_subset(j, :));\n",
        "    end\n",
        "end\n",
        "\n",
        "f = -ones(length(y_subset), 1); %-e\n",
        "\n",
        "Aeq = y_subset'; %y^t\n",
        "beq = 0; %restricciones de igualdad\n",
        "lb = zeros(length(y_subset), 1); %restricciones de desigualdad\n",
        "\n",
        "% Resolver el problema cuadrático\n",
        "options = optimoptions('quadprog', 'Algorithm', 'interior-point-convex');\n",
        "alpha_optimal = quadprog(H, f, [], [], Aeq, beq, lb, [], [], options);\n",
        "\n",
        "fprintf('Resultado de la optimización:\\n');\n",
        "fprintf('alpha_optimal = \\n');\n",
        "fprintf('%.15f\\n', alpha_optimal);\n",
        "\n",
        "% Valor de la función objetivo\n",
        "value = 0.5 * alpha_optimal' * H * alpha_optimal + f' * alpha_optimal;\n",
        "fprintf('Valor de la función objetivo = \\n');\n",
        "fprintf('%.15f\\n', value);\n",
        "\n",
        "% Encontrar los alphas mayores que 0\n",
        "indices_alpha_positivos = find(alpha_optimal > 0);\n",
        "fprintf('Valores de alpha mayores que 0:\\n');\n",
        "\n",
        "alpha_optimos = alpha_optimal(indices_alpha_positivos);\n",
        "disp(alpha_optimos);\n",
        "\n",
        "% Vectores de Soporte-------------------------------------------------\n",
        "X_filas_alpha_positivos = X_subset(indices_alpha_positivos, :);\n",
        "\n",
        "fprintf('Vectores de Soporte:\\n');\n",
        "disp(X_filas_alpha_positivos);\n",
        "\n",
        "save('soluciones_2.mat', 'alpha_optimos', 'X_filas_alpha_positivos');\n"
      ],
      "metadata": {
        "id": "txyvt-lQpgEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mat_data = scipy.io.loadmat('soluciones_2 .mat')\n",
        "\n",
        "alpha = mat_data['alpha_optimos']\n",
        "vectores = mat_data['X_filas_alpha_positivos']\n",
        "\n",
        "print(vectores)\n",
        "print(alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs-ePVZyESKc",
        "outputId": "0d911787-d48a-4ee1-d3d4-22265cfe46a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "[[5.84523413e+00]\n",
            " [5.55640145e+00]\n",
            " [1.29701221e+01]\n",
            " [3.75867148e+00]\n",
            " [7.47048292e+00]\n",
            " [1.15524681e+01]\n",
            " [1.33605497e+01]\n",
            " [2.04400073e+00]\n",
            " [5.88151955e+00]\n",
            " [3.60244264e+00]\n",
            " [2.54569655e+00]\n",
            " [4.13136113e+00]\n",
            " [2.91954392e+00]\n",
            " [1.82916283e+01]\n",
            " [2.19760510e+00]\n",
            " [4.12769090e+00]\n",
            " [1.99298353e+01]\n",
            " [3.51490628e+00]\n",
            " [1.42448767e+02]\n",
            " [3.21600899e+00]\n",
            " [1.55670832e+08]\n",
            " [2.93164916e+00]\n",
            " [7.47771862e+07]\n",
            " [1.12967414e+01]\n",
            " [4.12866852e+00]\n",
            " [4.11374233e+00]\n",
            " [1.00868536e+01]\n",
            " [5.97050735e+07]\n",
            " [9.89424787e+00]\n",
            " [2.06195912e+00]\n",
            " [2.95879011e+00]\n",
            " [2.43613576e+00]\n",
            " [2.88186946e+00]\n",
            " [8.99051277e+07]\n",
            " [3.12405226e+01]\n",
            " [8.31035557e+00]\n",
            " [7.62586372e+00]\n",
            " [5.05527396e+00]\n",
            " [4.15643606e+00]\n",
            " [3.55377934e+00]\n",
            " [1.01396233e+01]\n",
            " [1.01942409e+01]\n",
            " [3.41812256e+00]\n",
            " [1.97791574e+00]\n",
            " [5.00235046e+00]\n",
            " [4.93858948e+00]\n",
            " [4.51680712e+00]\n",
            " [4.28317275e+00]\n",
            " [1.73615249e+00]\n",
            " [3.79904228e+00]\n",
            " [3.21143746e+00]\n",
            " [2.66606618e+01]\n",
            " [6.42172935e+00]\n",
            " [6.88670874e+00]\n",
            " [4.68327421e+00]\n",
            " [2.66178116e+00]\n",
            " [2.52162795e+04]\n",
            " [3.22130316e+00]\n",
            " [6.02738628e+00]\n",
            " [4.07258541e+00]\n",
            " [5.74494088e+02]\n",
            " [2.52755485e+01]\n",
            " [1.48862205e+01]\n",
            " [2.36428679e+01]\n",
            " [9.04737470e+00]\n",
            " [1.67948426e+01]\n",
            " [1.48135610e+01]\n",
            " [2.62632918e+00]\n",
            " [3.30908160e+00]\n",
            " [5.91566963e+02]\n",
            " [9.01069373e+00]\n",
            " [5.49747324e+01]\n",
            " [2.50917519e+00]\n",
            " [1.69406208e+04]\n",
            " [7.19956150e+00]\n",
            " [5.14074029e+00]\n",
            " [1.14317361e+07]\n",
            " [1.28958525e+05]\n",
            " [7.81090631e+00]\n",
            " [1.19010401e+01]\n",
            " [4.77376371e+00]\n",
            " [3.57632905e+00]\n",
            " [6.28433901e+00]\n",
            " [1.54608154e+08]\n",
            " [8.76104986e+00]\n",
            " [6.16891862e+00]\n",
            " [6.03293944e+00]\n",
            " [1.27916893e+01]\n",
            " [2.13845644e+08]\n",
            " [3.44197386e+01]\n",
            " [7.52207427e+00]\n",
            " [1.04511863e+02]\n",
            " [2.66606612e+01]\n",
            " [4.73346863e+00]\n",
            " [5.56081928e+00]\n",
            " [3.04048445e+01]\n",
            " [1.25276498e+02]\n",
            " [8.06049504e+01]\n",
            " [1.09412740e+01]\n",
            " [9.08467625e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar condiciones KKT"
      ],
      "metadata": {
        "id": "KYImgwsEOBf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condicion = True\n",
        "\n",
        "for alpha_i, x_i, y_i in zip(alpha, vectores, y_subset):\n",
        "    condiciones_kkt = alpha_i * (y_i * (np.dot(w_optimal, x_i) + b_optimal) - 1)\n",
        "\n",
        "    if abs(condiciones_kkt) >= 1e-5:\n",
        "        condicion = False\n",
        "        break\n",
        "\n",
        "# Print message if all conditions are met\n",
        "if condicion:\n",
        "    print(\"Todos los vectores satisfacen las condiciones\")\n",
        "else:\n",
        "    print(\"No todos los vectores satisfacen las condiciones\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si_EvWbyOABm",
        "outputId": "902a38fa-4d86-4542-a789-6bbdd30da239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los vectores satisfacen las condiciones\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error de Clasificación"
      ],
      "metadata": {
        "id": "9g5XYBkQOIdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_values = np.dot(X_test, w_optimal) + b_optimal\n",
        "y_pred = np.sign(decision_values)\n",
        "\n",
        "error_rate = 1 - np.sum(y_pred == y_test) / len(y_test)\n",
        "\n",
        "print(f\"Classification Error Rate: {error_rate:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QznJEeoFOGXg",
        "outputId": "96bc59a5-b3a5-4e3d-b3a4-ada054312a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Error Rate: 40.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se observa que al ser clases no separables, el error de clasificación es del 40% y hay muchos vectores de soporte."
      ],
      "metadata": {
        "id": "rKWYRa5pFGyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables de Holgura"
      ],
      "metadata": {
        "id": "vHsslRIBx9YU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$min \\frac{1}{2} ||w||^2 + c ∑_{i=1}^n \\xi^2$\n",
        "\n",
        "$s.a \\quad y_i(w^tx_i + b) \\geq 1 - \\xi_1; \\quad \\xi_i \\geq 0  \\quad \\forall i = 1, \\cdots, n$\n",
        "\n",
        "donde **c>0** es el parámetro de penalización."
      ],
      "metadata": {
        "id": "YeNSz87LPPDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def holgura(C):\n",
        "  w = cp.Variable(X_subset.shape[1])\n",
        "  b = cp.Variable()\n",
        "  s = cp.Variable(len(y_subset))\n",
        "  # Restricciones\n",
        "  constraints = [y_subset[i] * (X_subset[i] @ w + b) >= 1 - s[i]for i in range(len(y_subset))]\n",
        "\n",
        "  # Función objetivo\n",
        "  objective = cp.Minimize(0.5 * cp.norm(w)**2 + C*cp.norm(s)**2)\n",
        "\n",
        "  # Problema de optimización\n",
        "  problem = cp.Problem(objective, constraints)\n",
        "\n",
        "  # Resolver el problema\n",
        "  problem.solve()\n",
        "\n",
        "  # Obtener los valores óptimos\n",
        "  w_optimal = w.value\n",
        "  b_optimal = b.value\n",
        "  s_optimal = s.value\n",
        "\n",
        "  return w_optimal, b_optimal\n",
        "\n",
        "C = [1/10**i for i in range(0, 10)]\n",
        "C.extend([20, 100])\n",
        "\n",
        "def clasificacion(w_optimal, b_optimal):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
        "  decision_values = np.dot(X_test, w_optimal) + b_optimal\n",
        "  y_pred = np.sign(decision_values)\n",
        "  error_rate = 1 - np.sum(y_pred == y_test) / len(y_test)\n",
        "\n",
        "  return error_rate\n",
        "\n",
        "for c in C:\n",
        "  w, b = holgura(c)\n",
        "  error = clasificacion(w, b)\n",
        "  print(\"Para C = \", c)\n",
        "  print(\"Coeficientes: \", w)\n",
        "  print(\"b: \", b)\n",
        "  print(\"Error: \", error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK0_blU9yAtJ",
        "outputId": "59ab0106-beda-4271-efa6-9ffff8565313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para C =  1.0\n",
            "Coeficientes:  [2.96288568e-09 1.02927454e-09 7.30370008e-09 4.22609313e-09]\n",
            "b:  3.1763478560942735\n",
            "Error:  0.4\n",
            "Para C =  0.1\n",
            "Coeficientes:  [-2.27723814e-08 -8.74860172e-09 -2.74071960e-08 -1.41422856e-08]\n",
            "b:  2.9268748683851658\n",
            "Error:  0.4\n",
            "Para C =  0.01\n",
            "Coeficientes:  [-9.21463446e-10  3.82468577e-11 -9.70609704e-09 -6.90829115e-09]\n",
            "b:  2.8727395274830383\n",
            "Error:  0.4\n",
            "Para C =  0.001\n",
            "Coeficientes:  [-1.44418972e-09 -4.71241035e-10 -3.72710420e-09 -2.32399532e-09]\n",
            "b:  2.8643424376765765\n",
            "Error:  0.4\n",
            "Para C =  0.0001\n",
            "Coeficientes:  [-3.10942834e-09 -1.01808364e-09 -9.77701507e-09 -6.07801140e-09]\n",
            "b:  2.8708398512158126\n",
            "Error:  0.4\n",
            "Para C =  1e-05\n",
            "Coeficientes:  [-2.68143654e-08 -9.31882501e-09 -7.37314454e-08 -4.53262731e-08]\n",
            "b:  2.8087598315635427\n",
            "Error:  0.4\n",
            "Para C =  1e-06\n",
            "Coeficientes:  [-1.07627256e-07 -3.76714125e-08 -2.99397203e-07 -1.84235622e-07]\n",
            "b:  2.8464031178804934\n",
            "Error:  0.4\n",
            "Para C =  1e-07\n",
            "Coeficientes:  [1.83029786e-08 6.48966511e-09 4.89735016e-08 2.99206403e-08]\n",
            "b:  2.4185972853716757\n",
            "Error:  0.4\n",
            "Para C =  1e-08\n",
            "Coeficientes:  [-1.14002130e-07 -3.93333933e-08 -3.22124749e-07 -1.98660554e-07]\n",
            "b:  2.148547492613536\n",
            "Error:  0.4\n",
            "Para C =  1e-09\n",
            "Coeficientes:  [-1.73805656e-06 -6.05941858e-07 -4.79902205e-06 -2.94794077e-06]\n",
            "b:  2.6972026353290968\n",
            "Error:  0.4\n",
            "Para C =  20\n",
            "Coeficientes:  [ 4.70426004e-08 -2.10686392e-07  1.33913672e-06  8.85807827e-07]\n",
            "b:  4.578652259742932\n",
            "Error:  0.4\n",
            "Para C =  100\n",
            "Coeficientes:  [-2.32081144e-08 -2.57626180e-09 -1.03063189e-07 -6.33904723e-08]\n",
            "b:  6.4729305788316145\n",
            "Error:  0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se observa que el error de clasificación no mejora cuando se varía el valor de *c*."
      ],
      "metadata": {
        "id": "jdXL_CTVEJMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caso No separable\n",
        "**Problema Primal**\n",
        "\n",
        "$min \\frac{1}{2} ||w||^2 + c ∑_{i=1}^n \\xi^2$\n",
        "\n",
        "$s.a \\quad y_i(w \\phi (x_i) + b) \\geq 1 - \\xi_1; \\quad \\xi_i \\geq 0  \\quad \\forall i = 1, \\cdots, n$"
      ],
      "metadata": {
        "id": "YkXY9rE-Q77m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones de los experimentos anteriores"
      ],
      "metadata": {
        "id": "HqY_gXyDJ5Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acuerdo con observado en los experimentos anteriores se puede concluir que:\n",
        "\n",
        "*   Cuando los clases son linealmente separables se observaron pocos vectores de soporte. En cambio, para clases no separables el número de vectores de soporte era mucho más grande.\n",
        "*   Se observó que para las clases separables los valores del vector *w* eran mayores que 0, lo cual indicaba un espacio de separabilidad entre los márgenes. Sin embargo, para clases no separables los coeficientes de *w* son muy cercanos a 0, esto sugiere que no hay espacio entre los márgenes.\n",
        "* Para clases separables el error de clasificación es nulo, sin embargo, para las no separables es del 40%.\n",
        "* Al variar el *c* se observó que no cambió el error de clasificación puesto que se usaba el kernel lineal. Sin embargo, los coeficientes de *w* si varíaban. Se sugiere introducir kernels para mejorar la clasificación.\n"
      ],
      "metadata": {
        "id": "V1IxyNA8KCnw"
      }
    }
  ]
}